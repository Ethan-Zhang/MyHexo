{"meta":{"version":1,"warehouse":"1.0.3"},"models":{"Asset":[{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":1},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":1},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","path":"vendors/jquery_lazyload/jquery.scrollstop.js","modified":1},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","path":"vendors/jquery_lazyload/jquery.lazyload.js","modified":1},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","path":"vendors/jquery_lazyload/bower.json","modified":1},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","path":"vendors/jquery_lazyload/README.md","modified":1},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","path":"vendors/jquery_lazyload/CONTRIBUTING.md","modified":1},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","path":"vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","path":"vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","path":"vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":1},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","path":"vendors/font-awesome/fonts/FontAwesome.otf","modified":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","path":"vendors/font-awesome/css/font-awesome.min.css","modified":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","path":"vendors/font-awesome/css/font-awesome.css.map","modified":1},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","path":"vendors/font-awesome/css/font-awesome.css","modified":1},{"_id":"themes/next/source/vendors/font-awesome/bower.json","path":"vendors/font-awesome/bower.json","modified":1},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","path":"vendors/font-awesome/HELP-US-OUT.txt","modified":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","path":"vendors/fastclick/lib/fastclick.min.js","modified":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","path":"vendors/fastclick/lib/fastclick.js","modified":1},{"_id":"themes/next/source/vendors/fastclick/bower.json","path":"vendors/fastclick/bower.json","modified":1},{"_id":"themes/next/source/vendors/fastclick/README.md","path":"vendors/fastclick/README.md","modified":1},{"_id":"themes/next/source/vendors/fastclick/LICENSE","path":"vendors/fastclick/LICENSE","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":1},{"_id":"themes/next/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1},{"_id":"themes/next/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":1},{"_id":"themes/next/source/js/helpers.js","path":"js/helpers.js","modified":1},{"_id":"themes/next/source/js/fancy-box.js","path":"js/fancy-box.js","modified":1},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":1},{"_id":"themes/next/source/js/bootstrap.js","path":"js/bootstrap.js","modified":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1},{"_id":"source/CNAME","path":"CNAME","modified":1}],"Cache":[{"_id":"source/404.html","shasum":"d806011f2f4a8f954cfee9d59a1b31aca8c0d844","modified":1452223934000},{"_id":"source/CNAME","shasum":"39b6ab6708636c1c986de9a5479b186c45047e29","modified":1453082526000},{"_id":"source/_posts/Change-to-GitPage.md","shasum":"19a4a632cea6f07cab00df87bdf64966116ef522","modified":1453260242000},{"_id":"source/_posts/OpenStack基础组件kombu杂谈.md","shasum":"2f07744811b89685471d53a3df0012a267b3535e","modified":1453264089000},{"_id":"source/_posts/Linux的IO复用.md","shasum":"07246464e0354862c96865fabbd8c0b011cdd0f0","modified":1453264039000},{"_id":"source/_posts/Python多进程log日志切分错误的解决方案.md","shasum":"7caad1b54dd8a2ac1c70ff4fedf6943e0a0c4bf9","modified":1453864981000},{"_id":"source/_posts/Tornado生产骨架——mownfish介绍.md","shasum":"a0ac87bd3ae7badc8bc860ae05b53730b1e409ed","modified":1453718747000},{"_id":"source/_posts/OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user-data.md","shasum":"07d7f884b01e40a7b830963896bfc0baf810d590","modified":1453264309000},{"_id":"source/_posts/memcached几个容易被忽略但非常有用的命令.md","shasum":"c59e1e38e9acf95c15917013d80a93e5f50f34dd","modified":1453264069000},{"_id":"source/_posts/OpenStack虚拟机的用户客制化方法（User-Data）.md","shasum":"90b76ff6d9b20cd3e3691a43858df712fa950ea9","modified":1453264124000},{"_id":"source/_posts/黑科技-巧用二级指针删除单向链表.md","shasum":"2c4e134b9fde9fe3b31f511a1bae1e63722e6b4c","modified":1453778982000},{"_id":"source/_posts/谈谈如何设计秒杀服务.md","shasum":"6d5b22319ac1da9467782e1c6213d521eb7e7c30","modified":1453718694000},{"_id":"source/_posts/多线程C调用python-api的陷阱.md","shasum":"0cb92675e4115897e69404274e03e5ac1b4554d6","modified":1453263982000},{"_id":"source/_posts/当黑客马拉松遇上全栈工程师.md","shasum":"f721ab67e7ffcb272d7f7d97e79a9546aef6f77e","modified":1453260310000},{"_id":"source/categories/index.md","shasum":"33d62979645424bbe109c8a44da6fc139dc586fa","modified":1452223455000},{"_id":"source/tags/index.md","shasum":"278d51731fb327c7310b76ab951eb9ee070c69f5","modified":1452224055000},{"_id":"themes/next/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1452167139000},{"_id":"themes/next/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1452167139000},{"_id":"themes/next/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1452167139000},{"_id":"themes/next/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1452167139000},{"_id":"themes/next/source/css/_variables/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1452167139000},{"_id":"themes/next/README.en.md","shasum":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1452167139000},{"_id":"themes/next/README.md","shasum":"0b709591995001cd860384d6c189e51d91690714","modified":1452167139000},{"_id":"themes/next/_config.yml","shasum":"cc749b412b9737a70858a6ed8112ac8e95be73aa","modified":1453865957000},{"_id":"themes/next/bower.json","shasum":"4a53cab758c7d69be2ce773b2afff7dd962b7cb0","modified":1452167139000},{"_id":"themes/next/languages/de.yml","shasum":"7a8de0e5665c52a1bf168c1e7dd222c8a74fb0ab","modified":1452167139000},{"_id":"themes/next/languages/default.yml","shasum":"f57623e47f533c8d53d859628fa6a368a5298a00","modified":1452167139000},{"_id":"themes/next/languages/en.yml","shasum":"f57623e47f533c8d53d859628fa6a368a5298a00","modified":1452167139000},{"_id":"themes/next/languages/pt.yml","shasum":"8e38fdf3a5232b428d2e4a641666dbabab87c3d1","modified":1452167139000},{"_id":"themes/next/languages/zh-Hans.yml","shasum":"c01d18d5c3837bb04d263e845db8f6827fde65de","modified":1452167139000},{"_id":"themes/next/languages/ru.yml","shasum":"1d1b158f9cff1b38978086043f299b3fc590e007","modified":1452167139000},{"_id":"themes/next/languages/fr-FR.yml","shasum":"2cec663601ac8d178e97aee91d967fa99a95ad4e","modified":1452167139000},{"_id":"themes/next/languages/zh-tw.yml","shasum":"42ba1d0c6b6026ba1e613ad11efb75432a8132ac","modified":1452167139000},{"_id":"themes/next/languages/zh-hk.yml","shasum":"248b88c825fde8e35839f3954d38df4e72a0537c","modified":1452167139000},{"_id":"themes/next/layout/_layout.swig","shasum":"4efe52f310b797f4bdedacbd979caf285d2bc731","modified":1453865255000},{"_id":"themes/next/layout/_macro/post-collapse.swig","shasum":"9032ae9056cb19b4c2d069d66ead7abf828f9922","modified":1452167139000},{"_id":"themes/next/layout/_macro/post.swig","shasum":"f32eaace2afb0450cf230f96ee8c87f20d6a9072","modified":1452167139000},{"_id":"themes/next/layout/_partials/comments.swig","shasum":"a612a4eca51ffc87b53a5470b451071a7ad6a031","modified":1452167139000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","shasum":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1452167139000},{"_id":"themes/next/layout/_macro/sidebar.swig","shasum":"88e179ff660874135b17d0febc91d04749053a73","modified":1452167139000},{"_id":"themes/next/layout/_partials/head.swig","shasum":"fcef099c268bd4964e65cfe3109e3fe99d0b925c","modified":1452167139000},{"_id":"themes/next/layout/_partials/old-browsers.swig","shasum":"dbbfea810bf3a2ed9c83b9a6683037175aacfc67","modified":1452167139000},{"_id":"themes/next/layout/_partials/footer.swig","shasum":"473d0a5d28cfd701999bc43778dba38cb35a326b","modified":1452508936000},{"_id":"themes/next/layout/_partials/header.swig","shasum":"476333c49a1e7e0402a68a826f67527ac258969d","modified":1452167139000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","shasum":"00c2b49f6289198b0b2b4e157e4ee783277f32a7","modified":1452167139000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","shasum":"eefe2388ff3d424694045eda21346989b123977c","modified":1452167139000},{"_id":"themes/next/layout/_partials/search.swig","shasum":"64f14da26792a17bc27836c4e9d83190175f36e6","modified":1452167139000},{"_id":"themes/next/layout/_partials/pagination.swig","shasum":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1452167139000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","shasum":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1452167139000},{"_id":"themes/next/layout/_scripts/analytics/facebook-sdk.swig","shasum":"334176d838ee528e58468d8bc74ff3a6d3f25b2b","modified":1452167139000},{"_id":"themes/next/layout/_scripts/analytics/baidu-analytics.swig","shasum":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1452167139000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","shasum":"63315fcf210799f894208c9f512737096df84962","modified":1452167139000},{"_id":"themes/next/layout/_scripts/analytics/google-analytics.swig","shasum":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1452167139000},{"_id":"themes/next/layout/_scripts/analytics.swig","shasum":"33ca06b9bd9a15a19432d5396b85bd319f017319","modified":1452167139000},{"_id":"themes/next/layout/_scripts/baidushare.swig","shasum":"d726361945437cf6e48067b3dd041b7e36e98d85","modified":1452167139000},{"_id":"themes/next/layout/_scripts/bootstrap.scrollspy.swig","shasum":"85295f126836b95f0837d03e58228bb3cf8c4490","modified":1452167139000},{"_id":"themes/next/layout/_scripts/comments/disqus.swig","shasum":"3491d3cebabc8a28857200db28a1be65aad6adc2","modified":1452167139000},{"_id":"themes/next/layout/_scripts/comments/duoshuo.swig","shasum":"44e3d567fd49c2a093f4a0a8af9f00542c935a58","modified":1452167139000},{"_id":"themes/next/layout/_scripts/fancy-box.swig","shasum":"41b4ff1446060c88c33bf666a32277dcf12129f0","modified":1452167139000},{"_id":"themes/next/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1452167139000},{"_id":"themes/next/layout/_scripts/motion.swig","shasum":"0d9761e3b1bb9e666ccc71bad59f035deb5a88c6","modified":1452167139000},{"_id":"themes/next/layout/_scripts/mathjax.swig","shasum":"df03220eb8526e17dc9c9f17780c2d6699367181","modified":1452167139000},{"_id":"themes/next/layout/archive.swig","shasum":"0c3ce594759f347ea90a4ce592a7a18e2ae4cc5c","modified":1452167139000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","shasum":"7a34b02808f144ee4a11032ae3a149eb634a7e82","modified":1452167139000},{"_id":"themes/next/layout/_scripts/tinysou.swig","shasum":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1452167139000},{"_id":"themes/next/layout/category.swig","shasum":"d6b3e1dc5e0b8deade9a084c463126e70188ee9b","modified":1452167139000},{"_id":"themes/next/layout/index.swig","shasum":"38b1ad401b748965369296b86327d23082a1fe93","modified":1452167139000},{"_id":"themes/next/layout/post.swig","shasum":"a84457e8ced46e63bc7a8a9e0541a6ba53122a92","modified":1452167139000},{"_id":"themes/next/scripts/filters/sticky.js","shasum":"6b1ea0c09105352813357d0fff4e1d3f4c821fa3","modified":1452167139000},{"_id":"themes/next/layout/page.swig","shasum":"8019d02232a6dd1a665b6a4d2daef8e5dd2f0049","modified":1452167139000},{"_id":"themes/next/scripts/merge-configs.js","shasum":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1452167139000},{"_id":"themes/next/scripts/tags/center-quote.js","shasum":"535fc542781021c4326dec24d8495cbb1387634a","modified":1452167139000},{"_id":"themes/next/scripts/tags/full-image.js","shasum":"3acce36db0feb11a982c6c799aa6b6b47df2827c","modified":1452167139000},{"_id":"themes/next/scripts/tags/group-pictures.js","shasum":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1452167139000},{"_id":"themes/next/layout/tag.swig","shasum":"aab44af54fcbc66fea4ad12b2767ffca3eadd451","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/back-to-top.styl","shasum":"88cd66910260006aa8e9e795df4948d4b67bfa11","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/buttons.styl","shasum":"81063e0979f04a0f9af37f321d7321dda9abf593","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/blockquote-center.styl","shasum":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/comments.styl","shasum":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/gallery.styl","shasum":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/group-pictures.styl","shasum":"1ee40743000173495728855f734081eb2b6167cc","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/duoshuo.styl","shasum":"2d2da815ab0981b219ea1973a4aedede48801411","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/jiathis.styl","shasum":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/posts-collapse.styl","shasum":"6750b61236eb359028da8f2c4765f7c89b03dc9a","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/pagination.styl","shasum":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/posts-type.styl","shasum":"40b593134bf96d1d6095b3439d47820659d7f10b","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/posts.styl","shasum":"b05ac51dd266d27f12e39e59a94383fe6474b7b3","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/posts-expand.styl","shasum":"672d5fa7e5b7642d86a4bda176b501508b54860f","modified":1452167139000},{"_id":"themes/next/source/css/_common/_component/tag-cloud.styl","shasum":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1452167139000},{"_id":"themes/next/source/css/_common/_core/base.styl","shasum":"388aa7c69c97728c64941db01e0f29a88837120c","modified":1452167139000},{"_id":"themes/next/source/css/_common/_core/helpers.styl","shasum":"d339d114e52a9abbc797ec236a8a770c29e288a6","modified":1452167139000},{"_id":"themes/next/source/css/_common/_core/scaffolding.styl","shasum":"1f8acb3331300eec696a09e7859e11f191e16d7f","modified":1452167139000},{"_id":"themes/next/source/css/_common/_core/normalize.styl","shasum":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1452167139000},{"_id":"themes/next/source/css/_common/_core/tables.styl","shasum":"5f766cf26f966dbf9dcfe681f40ab9032e3e8a08","modified":1452167139000},{"_id":"themes/next/source/css/_common/_fonts/icon-default.styl","shasum":"8b809aef383bebaeb3f282b47675f3a364ce3569","modified":1452167139000},{"_id":"themes/next/source/css/_common/_fonts/icon-feather.styl","shasum":"80413afacfa656322100ce1900fed1ebcd8f8f44","modified":1452167139000},{"_id":"themes/next/source/css/_common/_fonts/icon-font.styl","shasum":"ec3f86739bede393cafcd3e31052c01115ae20d6","modified":1452167139000},{"_id":"themes/next/source/css/_common/_page/archive.styl","shasum":"dff879f55ca65fa79c07e9098719e53eeea7ac88","modified":1452167139000},{"_id":"themes/next/source/css/_common/_fonts/icon-linecons.styl","shasum":"9cdbedb3627ac941cfb063b152abe5a75c3c699a","modified":1452167139000},{"_id":"themes/next/source/css/_common/_page/categories.styl","shasum":"4f696a2eaeee2f214adcf273eab25c62a398077a","modified":1452167139000},{"_id":"themes/next/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"249f75bafa26b99d272352c0646e7497ea680b39","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/body.styl","shasum":"ca1a4766cbe25baac757c6b47a4858d221afdc40","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/header.styl","shasum":"a6aa8a56f9f645ae5a76a1034f79adf73b053aa0","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/footer.styl","shasum":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1452167139000},{"_id":"themes/next/source/css/_common/_page/post-detail.styl","shasum":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/layout.styl","shasum":"03ae7b808dde9065412968aa69916162e790455d","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/media.styl","shasum":"fa9809d2ecc753cf32f70803c1d0821c405211f4","modified":1452167139000},{"_id":"themes/next/source/css/_common/_section/sidebar.styl","shasum":"bc106c3e759cd752c2b4c53ac27bc5ef5e3b18ea","modified":1452167139000},{"_id":"themes/next/source/css/_custom/custom.styl","shasum":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1452167139000},{"_id":"themes/next/source/css/_common/_vendor/highlight/theme.styl","shasum":"ae19721ceee5ba460e131cb2427dae3c1ff39d6f","modified":1452167139000},{"_id":"themes/next/source/css/_common/_vendor/highlight/highlight.styl","shasum":"6242be4307a3b3dafc14e556f51c8875c41a1ddd","modified":1452167139000},{"_id":"themes/next/source/css/_mixins/base.styl","shasum":"4e49707c99c8bbcfa0a607dfdaff0fbb7dffd2a3","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","shasum":"d50c2a9ae363d26ed2e9bc226a9dc7abeb9ace1b","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","shasum":"1631a430655eadb485574d1a9bedd49460988b11","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","shasum":"5a8036fc61207ca0fe38c9782ed2f686fbf764be","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","shasum":"4303776991ef28f5742ca51c7dffe6f12f0acf34","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","shasum":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","shasum":"fc7d96b897290dbd93bc8c515a2058fc4c374ea7","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/default/_search.styl","shasum":"c524bccdc554349106d1c8be9c3f275d4c0d4281","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/default/_menu.styl","shasum":"4bba29cece65ffc5122f4e052063dea4439fe4ae","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/default/_logo.styl","shasum":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1452167139000},{"_id":"themes/next/source/css/_variables/Mist.styl","shasum":"9f8791860cc1ca724d2dfe609e8cd6abc44d6926","modified":1452167139000},{"_id":"themes/next/source/css/_schemes/default/index.styl","shasum":"159464cb8a7e01e32db9ec70dec391ec70a72f9c","modified":1452167139000},{"_id":"themes/next/source/css/_variables/default.styl","shasum":"8ec3307fe42d738b1bbda4b6419d0995f5560222","modified":1452167139000},{"_id":"themes/next/source/css/_variables/base.styl","shasum":"f532d6b0f961a8f3867c06e132233286f110180d","modified":1452167139000},{"_id":"themes/next/source/css/main.styl","shasum":"56dacee56c5eaa4b2676d196452314fb50f758aa","modified":1452167139000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1452167139000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1452167139000},{"_id":"themes/next/source/images/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1452167139000},{"_id":"themes/next/source/images/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1452167139000},{"_id":"themes/next/source/images/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1452167139000},{"_id":"themes/next/source/images/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1452167139000},{"_id":"themes/next/source/images/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1452167139000},{"_id":"themes/next/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1452167139000},{"_id":"themes/next/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1452167139000},{"_id":"themes/next/source/images/quote-l.svg","shasum":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1452167139000},{"_id":"themes/next/source/images/quote-r.svg","shasum":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1452167139000},{"_id":"themes/next/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1452167139000},{"_id":"themes/next/source/js/bootstrap.js","shasum":"f9b637b6d064f728d7dc2b6b5058a006a4454299","modified":1452167139000},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625","modified":1452167139000},{"_id":"themes/next/source/js/fancy-box.js","shasum":"b5fa638ed371b5f658b0826ec4afee25d9986ef2","modified":1452167139000},{"_id":"themes/next/source/js/helpers.js","shasum":"c15216ef897334362789ba37464298948b2eef95","modified":1452167139000},{"_id":"themes/next/source/js/hook-duoshuo.js","shasum":"ccb32e0a1acf798337c9697e1aab5484b52f9df4","modified":1452167139000},{"_id":"themes/next/source/js/motion.js","shasum":"b4132517fe499538ad725094593fb7ead8c04bf7","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1452167139000},{"_id":"themes/next/source/js/ua-parser.min.js","shasum":"1148fa2bcb8b2e40c31e5f597bf794a57369a2e6","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1452167139000},{"_id":"themes/next/source/vendors/fastclick/LICENSE","shasum":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"53360764b429c212f424399384417ccc233bb3be","modified":1452167139000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1452167139000},{"_id":"themes/next/source/vendors/fastclick/README.md","shasum":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1452167139000},{"_id":"themes/next/source/vendors/fastclick/bower.json","shasum":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1452167139000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","shasum":"69a4c537d167b68a0ccf1c6febd138aeffca60d6","modified":1452167139000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","shasum":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/bower.json","shasum":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","shasum":"3b87c2560832748cd06f9bfd2fd6ea8edbdae8c7","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","shasum":"0189d278706509412bac4745f96c83984e1d59f4","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","shasum":"05ea25bc9b3ac48993e1fee322d3bc94b49a6e22","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","shasum":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","shasum":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","shasum":"895d50fa29759af7835256522e9dd7dac597765c","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","shasum":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","shasum":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","shasum":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1452167139000},{"_id":"themes/next/source/vendors/velocity/bower.json","shasum":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1452167139000},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1452167139000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1452167139000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1452167139000},{"_id":"themes/next/test/helpers.js","shasum":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1452167139000},{"_id":"themes/next/test/intern.js","shasum":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","shasum":"0112e96f327d413938d37c1693806f468ffdbace","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","shasum":"b3c2f08e73320135b69c23a3908b87a12053a2f6","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","shasum":"507970402e328b2baeb05bde73bf9ded4e2c3a2d","modified":1452167139000},{"_id":"themes/next/source/vendors/jquery/index.js","shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","shasum":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9","modified":1452167139000},{"_id":"themes/next/source/vendors/velocity/velocity.js","shasum":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1452167139000},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","shasum":"2b3c8ba7008cc014d8fb37abc6f9f49aeda83824","modified":1452167139000},{"_id":"public/vendors/velocity/velocity.ui.min.js","modified":1453867092286,"shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908"},{"_id":"public/vendors/velocity/velocity.ui.js","modified":1453867092293,"shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df"},{"_id":"public/vendors/velocity/velocity.min.js","modified":1453867092295,"shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6"},{"_id":"public/vendors/velocity/velocity.js","modified":1453867092301,"shasum":"9f08181baea0cc0e906703b7e5df9111b9ef3373"},{"_id":"public/vendors/velocity/bower.json","modified":1453867092303,"shasum":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409"},{"_id":"public/vendors/jquery_lazyload/jquery.scrollstop.js","modified":1453867092306,"shasum":"0e9a81785a011c98be5ea821a8ed7d411818cfd1"},{"_id":"public/vendors/jquery_lazyload/jquery.lazyload.js","modified":1453867092308,"shasum":"481fd478650e12b67c201a0ea41e92743f8b45a3"},{"_id":"public/vendors/jquery_lazyload/bower.json","modified":1453867092311,"shasum":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53"},{"_id":"public/vendors/jquery_lazyload/README.html","modified":1453867092337,"shasum":"c593e16f0d63d24b5d3933f3b9297884867ce4a0"},{"_id":"public/vendors/jquery_lazyload/CONTRIBUTING.html","modified":1453867092345,"shasum":"bf8e477ee2d81833cff12572a8a5f61abffc187c"},{"_id":"public/vendors/jquery/index.js","modified":1453867092348,"shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":1453867092354,"shasum":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":1453867092357,"shasum":"507970402e328b2baeb05bde73bf9ded4e2c3a2d"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":1453867092361,"shasum":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":1453867092365,"shasum":"2b3c8ba7008cc014d8fb37abc6f9f49aeda83824"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":1453867092369,"shasum":"b3c2f08e73320135b69c23a3908b87a12053a2f6"},{"_id":"public/vendors/font-awesome/fonts/FontAwesome.otf","modified":1453867092372,"shasum":"0112e96f327d413938d37c1693806f468ffdbace"},{"_id":"public/vendors/font-awesome/css/font-awesome.min.css","modified":1453867092374,"shasum":"05ea25bc9b3ac48993e1fee322d3bc94b49a6e22"},{"_id":"public/vendors/font-awesome/css/font-awesome.css.map","modified":1453867092378,"shasum":"0189d278706509412bac4745f96c83984e1d59f4"},{"_id":"public/vendors/font-awesome/css/font-awesome.css","modified":1453867092381,"shasum":"3b87c2560832748cd06f9bfd2fd6ea8edbdae8c7"},{"_id":"public/vendors/font-awesome/bower.json","modified":1453867092386,"shasum":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad"},{"_id":"public/vendors/font-awesome/HELP-US-OUT.txt","modified":1453867092389,"shasum":"69a4c537d167b68a0ccf1c6febd138aeffca60d6"},{"_id":"public/vendors/fastclick/lib/fastclick.min.js","modified":1453867092391,"shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18"},{"_id":"public/vendors/fastclick/lib/fastclick.js","modified":1453867092393,"shasum":"06cef196733a710e77ad7e386ced6963f092dc55"},{"_id":"public/vendors/fastclick/bower.json","modified":1453867092396,"shasum":"4dcecf83afddba148464d5339c93f6d0aa9f42e9"},{"_id":"public/vendors/fastclick/README.html","modified":1453867092407,"shasum":"627cdd7a56fc7d9c169b9f6afedd74f77e6d3d06"},{"_id":"public/vendors/fastclick/LICENSE","modified":1453867092425,"shasum":"dcd5b6b43095d9e90353a28b09cb269de8d4838e"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","modified":1453867092434,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","modified":1453867092439,"shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","modified":1453867092442,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1453867092444,"shasum":"53e194f4a72e649c04fb586dd57762b8c022800b"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1453867092446,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1453867092449,"shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1453867092453,"shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1453867092459,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1453867092465,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","modified":1453867092469,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","modified":1453867092472,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","modified":1453867092476,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","modified":1453867092489,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","modified":1453867092492,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/vendors/fancybox/source/blank.gif","modified":1453867092494,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/js/ua-parser.min.js","modified":1453867092496,"shasum":"1148fa2bcb8b2e40c31e5f597bf794a57369a2e6"},{"_id":"public/js/motion.js","modified":1453867092498,"shasum":"b4132517fe499538ad725094593fb7ead8c04bf7"},{"_id":"public/js/hook-duoshuo.js","modified":1453867092499,"shasum":"eedaf52377991728f1e3e94f2bc4bf23ec41ecea"},{"_id":"public/js/helpers.js","modified":1453867092501,"shasum":"c15216ef897334362789ba37464298948b2eef95"},{"_id":"public/js/fancy-box.js","modified":1453867092503,"shasum":"b5fa638ed371b5f658b0826ec4afee25d9986ef2"},{"_id":"public/js/bootstrap.scrollspy.js","modified":1453867092510,"shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625"},{"_id":"public/js/bootstrap.js","modified":1453867092514,"shasum":"f9b637b6d064f728d7dc2b6b5058a006a4454299"},{"_id":"public/images/searchicon.png","modified":1453867092518,"shasum":"67727a6a969be0b2659b908518fa6706eed307b8"},{"_id":"public/images/quote-r.svg","modified":1453867092521,"shasum":"e60ae504f9d99b712c793c3740c6b100d057d4ec"},{"_id":"public/images/quote-l.svg","modified":1453867092523,"shasum":"94e870b4c8c48da61d09522196d4dd40e277a98f"},{"_id":"public/images/placeholder.gif","modified":1453867092528,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/loading.gif","modified":1453867092530,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/cc-zero.svg","modified":1453867092533,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/images/cc-by.svg","modified":1453867092536,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/images/cc-by-sa.svg","modified":1453867092539,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/images/cc-by-nd.svg","modified":1453867092542,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/images/cc-by-nc.svg","modified":1453867092544,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/images/cc-by-nc-sa.svg","modified":1453867092549,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/images/cc-by-nc-nd.svg","modified":1453867092551,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/css/main.css","modified":1453867093064,"shasum":"4c2564863381341af0b883d08956b37cf0bce616"},{"_id":"public/CNAME","modified":1453867093196,"shasum":"39b6ab6708636c1c986de9a5479b186c45047e29"},{"_id":"public/404.html","modified":1453867093299,"shasum":"5a4c9c73cacdc6c50c1f4e0994268a72ccf90fb7"},{"_id":"public/tags/index.html","modified":1453867093359,"shasum":"9a98f6c649ea565608c5bafe9e3593a0782e0e39"},{"_id":"public/categories/index.html","modified":1453867093398,"shasum":"e8af9ae331c7f5033a676ef3057de8f7d3dd3873"},{"_id":"public/2016/01/07/Change-to-GitPage/index.html","modified":1453867093509,"shasum":"fecb80878beb1361d27951078944d53c95a326ef"},{"_id":"public/2015/04/20/当黑客马拉松遇上全栈工程师/index.html","modified":1453867093578,"shasum":"e4e284af122883fc696be2d998ad08a19d1cb72d"},{"_id":"public/2015/01/06/多线程C调用python-api的陷阱/index.html","modified":1453867093676,"shasum":"0a23f981dd7b078cdcf608ec079cef831a430bcc"},{"_id":"public/2014/07/26/谈谈如何设计秒杀服务/index.html","modified":1453867093748,"shasum":"814d461b055426d8012339b2b4120726781610b9"},{"_id":"public/2014/07/14/memcached几个容易被忽略但非常有用的命令/index.html","modified":1453867093819,"shasum":"85e1e4eb222b1541d6c57108c47c00ede6b0dade"},{"_id":"public/2014/02/17/黑科技-巧用二级指针删除单向链表/index.html","modified":1453867093898,"shasum":"9fcf5a8d11b1b28cfd5042183f99890d846ef9e0"},{"_id":"public/2013/12/18/OpenStack基础组件kombu杂谈/index.html","modified":1453867093983,"shasum":"012db7e8b09313e218941a21b205bbe90a0b37c7"},{"_id":"public/2013/12/03/Tornado生产骨架——mownfish介绍/index.html","modified":1453867094042,"shasum":"f2e6b44069da3600ea3eeede92ce81f66b8459ce"},{"_id":"public/2013/11/18/Python多进程log日志切分错误的解决方案/index.html","modified":1453867094129,"shasum":"469afd9c2d74d64ea55fa698b6f892a7c8cafe5f"},{"_id":"public/2013/03/11/Linux的IO复用/index.html","modified":1453867094196,"shasum":"043d1ac8ff9990dd38973c1f3cc2dd743a84bf45"},{"_id":"public/2012/10/31/OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user-data/index.html","modified":1453867094269,"shasum":"57f6dda4812784245c5183b901ae3016e7a22a68"},{"_id":"public/2012/10/30/OpenStack虚拟机的用户客制化方法（User-Data）/index.html","modified":1453867094324,"shasum":"4ad6c214df143bc763b28002f3b7584a9f4c753a"},{"_id":"public/archives/index.html","modified":1453867094398,"shasum":"2125a1016f066698128e1ec855b2a8ebd4006dc5"},{"_id":"public/archives/2012/index.html","modified":1453867094440,"shasum":"3a43a9d0a5088104aa48811054c0af4fbea21f93"},{"_id":"public/archives/2012/10/index.html","modified":1453867094497,"shasum":"a5533dcf1358b0182ccc0ca4c534123968a2a867"},{"_id":"public/archives/2013/index.html","modified":1453867094554,"shasum":"350c7bf641699c4c6648626b16cab0faa56f51d4"},{"_id":"public/archives/2013/03/index.html","modified":1453867094607,"shasum":"fb9c1dc416195d022177a66210212f8af1f3b343"},{"_id":"public/archives/2013/11/index.html","modified":1453867094647,"shasum":"5fc7df3f26300e6e7b79fcc0b8548b589174e774"},{"_id":"public/archives/2013/12/index.html","modified":1453867094696,"shasum":"45e5074b0896226b13ea2734eda0e34faf2710f0"},{"_id":"public/archives/2014/index.html","modified":1453867094758,"shasum":"0322b8689ba8e4ce20c75463de2a236a7d0787e4"},{"_id":"public/archives/2014/02/index.html","modified":1453867094805,"shasum":"77d0487c77942d9e72744d505cf4f8b4c310ec83"},{"_id":"public/archives/2014/07/index.html","modified":1453867094861,"shasum":"c5ef579cbfb108d53eb243ccf93b1ef87aa51884"},{"_id":"public/archives/2015/index.html","modified":1453867094907,"shasum":"094c0bdd22c80d2946bf80cba128d90cae30120f"},{"_id":"public/archives/2015/01/index.html","modified":1453867094951,"shasum":"1d6c169d5482be59f33de75c0655f96dc2184d91"},{"_id":"public/archives/2015/04/index.html","modified":1453867095010,"shasum":"912372c0d5f7b2bade7e046a43d29618080fa51b"},{"_id":"public/archives/2016/index.html","modified":1453867095054,"shasum":"db5a5de53f79035e3b3bb18433ca2235a543ade3"},{"_id":"public/archives/2016/01/index.html","modified":1453867095129,"shasum":"653a6e6bf57e230bb7e3632fedbfc8a92502ee31"},{"_id":"public/atom.xml","modified":1453867095132,"shasum":"537037b0ff98c4393a74e5cceae784b180980cfc"},{"_id":"public/tags/C-C/index.html","modified":1453867095182,"shasum":"9c961a5b56c30b39f6bcaa4bac0c4d78d010c7c4"},{"_id":"public/tags/算法/index.html","modified":1453867095223,"shasum":"4001ef9eb7162a59b87246d667fcf073958eb500"},{"_id":"public/tags/列表/index.html","modified":1453867095284,"shasum":"3e03c61a7fe3182c62e86203fd06018a3bcbd6bb"},{"_id":"public/tags/架构/index.html","modified":1453867095325,"shasum":"adbfeb8abc91e44bb27b5d3c45de9400f5392957"},{"_id":"public/tags/面试/index.html","modified":1453867095366,"shasum":"c563632776d2cb842a13b200153f7f27447e9b0b"},{"_id":"public/tags/感悟/index.html","modified":1453867095432,"shasum":"1809d078033b29255df97e3844e520f2d34dfee6"},{"_id":"public/tags/uwsgi/index.html","modified":1453867095473,"shasum":"f7722eaff2b8ba547e4501b2fb8a38ac9c565db5"},{"_id":"public/tags/多线程/index.html","modified":1453867095524,"shasum":"feec641d19e510dda691802e5e8760562f67ccba"},{"_id":"public/tags/Python-C-API/index.html","modified":1453867095580,"shasum":"b407fed8664619a77fcd79609d4c0e7a9b96c453"},{"_id":"public/tags/C调用Python/index.html","modified":1453867095616,"shasum":"e83105337c3b5842904da15085aed6201a92bd9f"},{"_id":"public/tags/memcached/index.html","modified":1453867095664,"shasum":"c9da23f1352f994b735b47929b8fc69e8babff0d"},{"_id":"public/tags/Tornado/index.html","modified":1453867095717,"shasum":"0a278d267ca59c6be4c66e72f2f5bd23ddd0e697"},{"_id":"public/tags/异步/index.html","modified":1453867095757,"shasum":"b60db95ee8ffcea45a5c05b0616f5cd35c0bf006"},{"_id":"public/tags/开源/index.html","modified":1453867095813,"shasum":"b1f2817c98428f577a164c69043a6077669cb69b"},{"_id":"public/tags/Python/index.html","modified":1453867095861,"shasum":"d011eb871a5b6e909718417b0018850192aa42f1"},{"_id":"public/tags/日志切分/index.html","modified":1453867095906,"shasum":"7de72bd35b43dc1a9bb0a364552855dc7866acb9"},{"_id":"public/tags/OpenStack/index.html","modified":1453867095968,"shasum":"801f96c73aa7f4a1a177cb5a36cd487771a74fdc"},{"_id":"public/tags/cloud-init/index.html","modified":1453867096010,"shasum":"9d87ec43ad9ba7b3d4fe2936b6d5743252009dd3"},{"_id":"public/tags/Nova/index.html","modified":1453867096057,"shasum":"afcbad34e1c9cc1c436a945e2179c944dba2a9e9"},{"_id":"public/tags/AMQP/index.html","modified":1453867096117,"shasum":"9b6cf11d05b56041fca0c79422afe7af436d0c10"},{"_id":"public/tags/kombu/index.html","modified":1453867096161,"shasum":"5be332a61a2ad1bbe37d74cdffd2474524974ca2"},{"_id":"public/tags/IO复用/index.html","modified":1453867096203,"shasum":"7d5e6c95d31db220ec0dd0f98a8739bda2787617"},{"_id":"public/tags/LINUX/index.html","modified":1453867096259,"shasum":"af788385f04d085ffe74afaddd2df5af44ee9b7f"},{"_id":"public/tags/高并发/index.html","modified":1453867096302,"shasum":"ce8a19a838e71c78d11d05b459be58fda6df189c"},{"_id":"public/index.html","modified":1453867096391,"shasum":"d59687e3f34e95305e1eb36365736320d0eb57c9"}],"Category":[],"Data":[],"Page":[{"_content":"<!DOCTYPE HTML>\n<html>\n    <head>\n        <meta http-equiv=\"content-type\"\n              content=\"text/html;charset=utf-8;\"/>\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n        <meta name=\"robots\" content=\"all\" />\n        <meta name=\"robots\" content=\"index,follow\"/>\n    </head>\n    <body>\n        <script type=\"text/javascript\"\n                src=\"http://www.qq.com/404/search_children.js\"\n                charset=\"utf-8\" homePageUrl=\"your site url \"\n                homePageName=\"回到我的主页\"></script>\n        </body>\n</html>\n","source":"404.html","raw":"<!DOCTYPE HTML>\n<html>\n    <head>\n        <meta http-equiv=\"content-type\"\n              content=\"text/html;charset=utf-8;\"/>\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n        <meta name=\"robots\" content=\"all\" />\n        <meta name=\"robots\" content=\"index,follow\"/>\n    </head>\n    <body>\n        <script type=\"text/javascript\"\n                src=\"http://www.qq.com/404/search_children.js\"\n                charset=\"utf-8\" homePageUrl=\"your site url \"\n                homePageName=\"回到我的主页\"></script>\n        </body>\n</html>\n","date":"2016-01-08T03:32:14.000Z","updated":"2016-01-08T03:32:14.000Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"cijwaxfci00000qi5guagkkdl"},{"title":"TagCloud","date":"2016-01-08T03:33:38.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"title: TagCloud\ndate: 2016-01-08 11:33:38\ntype: \"tags\"\n---\n","updated":"2016-01-08T03:34:15.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cijwaxfdn00010qi5717jqpng"},{"title":"categories","date":"2016-01-08T03:23:33.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2016-01-08 11:23:33\ntype: \"categories\"\ncomments: false\n---\n","updated":"2016-01-08T03:24:15.000Z","path":"categories/index.html","layout":"page","_id":"cijwaxfdq00020qi5e5asjgsx"}],"Post":[{"title":"黑科技--巧用二级指针删除单向链表","date":"2014-02-17T08:43:16.000Z","_content":"　　Linus大婶在[slashdot](http://meta.slashdot.org/story/12/10/11/0030249/linus-torvalds-answers-your-questions)上回答一些编程爱好者的提问，其中一个人问他什么样的代码是他所喜好的，大婶表述了自己一些观点之后，举了一个指针的例子，解释了什么才是**core low-level coding**。\n　　下面是Linus的教学原文及翻译\n>“At the opposite end of the spectrum, I actually wish more people understood the really core low-level kind of coding. Not big, complex stuff like the lockless name lookup, but simply good use of pointers-to-pointers etc. For example, I’ve seen too many people who delete a singly-linked list entry by keeping track of the “prev” entry, and then to delete the entry, doing something like。（在这段话的最后，我实际上希望更多的人了解什么是真正的核心底层代码。这并不像无锁文件名查询（注：可能是git源码里的设计）那样庞大、复杂，只是仅仅像诸如使用二级指针那样简单的技术。例如，我见过很多人在删除一个单项链表的时候，维护了一个”prev”表项指针，然后删除当前表项，就像这样）”\n```C\nif (prev)\n    prev->next = entry->next;\nelse\n    list_head = entry->next;\n```\n>and whenever I see code like that, I just go “This person doesn’t understand pointers”. And it’s sadly quite common.（当我看到这样的代码时，我就会想“这个人不了解指针”。令人难过的是这太常见了。）\nPeople who understand pointers just use a “pointer to the entry pointer”, and initialize that with the address of the list_head. And then as they traverse the list, they can remove the entry without using any conditionals, by just doing a “\\*pp = entry->next”. （了解指针的人会使用链表头的地址来初始化一个“指向节点指针的指针”。当遍历链表的时候，可以不用任何条件判断（注：指prev是否为链表头）就能移除某个节点，只要写“\\*pp = entry->next”)\nSo there’s lots of pride in doing the small details right. It may not be big and important code, but I do like seeing code where people really thought about the details, and clearly also were thinking about the compiler being able to generate efficient code (rather than hoping that the compiler is so smart that it can make efficient code *despite* the state of the original source code). （纠正细节是令人自豪的事。也许这段代码并非庞大和重要，**但我喜欢看那些注重代码细节的人写的代码，也就是清楚地了解如何才能编译出有效代码**（而不是寄望于聪明的编译器来产生有效代码，即使是那些原始的汇编代码））。\n\n　　Linus举了一个单向链表的例子，但给出的代码太短了，一般的人很难搞明白这两个代码后面的含义。正好，有个编程爱好者阅读了这段话，并给出了一个[比较完整的代码](http://wordaligned.org/articles/two-star-programming)。他的话我就不翻译了，下面给出代码说明。\n　　如果我们需要写一个remove_if(link\\*, rm_cond_func\\*)的函数，也就是传入一个单向链表，和一个自定义的是否删除的函数，然后返回处理后的链接。\n　　这个代码不难，基本上所有的教科书都会提供下面的代码示例，而这种写法也是大公司的面试题标准模板：\n```C\ntypedef struct node\n{\n    struct node * next;\n    ....\n} node;\n\ntypedef bool (* remove_fn)(node const * v);\n\n// Remove all nodes from the supplied list for which the\n// supplied remove function returns true.\n// Returns the new head of the list.\nnode * remove_if(node * head, remove_fn rm)\n{\n    for (node * prev = NULL, * curr = head; curr != NULL; )\n    {\n        node * const next = curr->next;\n        if (rm(curr))\n        {\n            if (prev)\n                prev->next = next;\n            else\n                head = next;\n            free(curr);\n        }\n        else\n            prev = curr;\n        curr = next;\n    }\n    return head;\n}\n```\n　　这里remove_fn由调用查提供的一个是否删除当前实体结点的函数指针，其会判断删除条件是否成立。这段代码维护了两个节点指针prev和curr，**标准的教科书写法——删除当前结点时，需要一个previous的指针，并且还要这里还需要做一个边界条件的判断——curr是否为链表头**。于是，要删除一个节点（不是表头），只要将前一个节点的next指向当前节点的next指向的对象，即下一个节点（即：prev->next = curr->next），然后释放当前节点。\n　　但在Linus看来，这是不懂指针的人的做法。那么，什么是core low-level coding呢？那就是**有效地利用二级指针，将其作为管理和操作链表的首要选项**。代码如下：\n```C\nvoid remove_if(node ** head, remove_fn rm)\n{\n    for (node** curr = head; *curr; )\n    {\n        node * entry = *curr;\n        if (rm(entry))\n        {\n            *curr = entry->next;\n            free(entry);\n        }\n        else\n            curr = &entry->next;\n    }\n}\n```\n<!--more-->\n　　同上一段代码有何改进呢？我们看到：不需要prev指针了，也不需要再去判断是否为链表头了，但是，**curr变成了一个指向指针的指针**。这正是这段程序的精妙之处。（注意，我所highlight的那三行代码）\n让我们来人肉跑一下这个代码，对于——\n* 删除节点是表头的情况，输入参数中传入head的二级指针，在for循环里将其初始化curr，然后entry就是\\*head(\\*curr)，我们马上删除它，那么第8行就等效于\\*head = (\\*head)->next，就是删除表头的实现。\n* 删除节点不是表头的情况，对于上面的代码，我们可以看到：\n\t1. （第12行）如果不删除当前结点 —— curr保存的是当前结点next指针的地址。\n\t2. （第5行） entry 保存了 \\*curr —— 这意味着在下一次循环：entry就是prev->next指针所指向的内存。\n\t3. （第8行）删除结点：\\*curr = entry->next; —— 于是：prev->next 指向了 entry -> next;\n　　是不是很巧妙？我们可以只用一个二级指针来操作链表，对所有节点都一样。\n　　如果你对上面的代码和描述理解上有困难的话，你可以看看下图的示意：\n![delete list](http://7xpwqp.com1.z0.glb.clouddn.com/2014-02-17-01)\n***\n__2016-01-36 更新__\n上面的一段解释是摘抄某个大神的解释，我想各位看的应该是晕晕乎乎的。其实不只是你，我每次隔一段时间再看这篇文章也还是要在想一遍到底是怎么回事。主要是这个示意图并不能很好的说明这个问题的根源。\n个人觉得这段程序并没有比上面用到prev指针的方法简便许多，主要是提供一种二级指针在hack linux中的常见的使用方法。\n二级指针，指向指针的指针，__拥有修改其指向的指针的能力__。这里我们主要看上面代码的第12行。二级指针curr，保存了当前节点entry的后继entry->next这个指针的地址，那么如果我们修改\\*curr，其实就是修改了entry->next这个指针的指向。这样的话，我们就不需要再声明一个prev指针变量，来保存节点前驱的地址，以便在删除当前节点的时候需要用前驱节点修改其后继节点的指向。去掉了prev这个前驱节点指针的变量，我们也就不再需要判断是否为header节点指针了。\n核心思想就是在涉及指针型变量的操作时，用二级指针可以方便的修改指针的指向。\n***\n\n***\n__2014-07-14 更新__　　memcached在删除hash_table中的单向表的某个节点的时候，也使用了二级指针的技术\n```C\nvoid assoc_delete(const char *key, const size_t nkey, const uint32_t hv) {\n    item **before = _hashitem_before(key, nkey, hv);\n\n    if (*before) {\n        item *nxt;\n        hash_items--;\n        /* The DTrace probe cannot be triggered as the last instruction\n         * due to possible tail-optimization by the compiler\n         */\n        MEMCACHED_ASSOC_DELETE(key, nkey, hash_items);\n        nxt = (*before)->h_next;\n        (*before)->h_next = 0;   /* probably pointless, but whatever. */\n        *before = nxt;\n        return;\n    }\n    /* Note:  we never actually get here.  the callers don't delete things\n       they can't find. */\n    assert(*before != 0);\n}\n```\n　　要实现单向列表的删除，按照一般教科书上的方法要声明两个指针，pre、cur，用来保存当前的节点和其前置的节点。但是如果应用二级指针，保存指向当前节点指针的地址\\*\\*before，则\\*before表示指向当前节点的指针，用这个方法可以非常优雅的解决问题。\n***\n","source":"_posts/黑科技-巧用二级指针删除单向链表.md","raw":"title: 黑科技--巧用二级指针删除单向链表\ndate: 2014-02-17 16:43:16\ntags: [C/C++, 算法, 列表]\n---\n　　Linus大婶在[slashdot](http://meta.slashdot.org/story/12/10/11/0030249/linus-torvalds-answers-your-questions)上回答一些编程爱好者的提问，其中一个人问他什么样的代码是他所喜好的，大婶表述了自己一些观点之后，举了一个指针的例子，解释了什么才是**core low-level coding**。\n　　下面是Linus的教学原文及翻译\n>“At the opposite end of the spectrum, I actually wish more people understood the really core low-level kind of coding. Not big, complex stuff like the lockless name lookup, but simply good use of pointers-to-pointers etc. For example, I’ve seen too many people who delete a singly-linked list entry by keeping track of the “prev” entry, and then to delete the entry, doing something like。（在这段话的最后，我实际上希望更多的人了解什么是真正的核心底层代码。这并不像无锁文件名查询（注：可能是git源码里的设计）那样庞大、复杂，只是仅仅像诸如使用二级指针那样简单的技术。例如，我见过很多人在删除一个单项链表的时候，维护了一个”prev”表项指针，然后删除当前表项，就像这样）”\n```C\nif (prev)\n    prev->next = entry->next;\nelse\n    list_head = entry->next;\n```\n>and whenever I see code like that, I just go “This person doesn’t understand pointers”. And it’s sadly quite common.（当我看到这样的代码时，我就会想“这个人不了解指针”。令人难过的是这太常见了。）\nPeople who understand pointers just use a “pointer to the entry pointer”, and initialize that with the address of the list_head. And then as they traverse the list, they can remove the entry without using any conditionals, by just doing a “\\*pp = entry->next”. （了解指针的人会使用链表头的地址来初始化一个“指向节点指针的指针”。当遍历链表的时候，可以不用任何条件判断（注：指prev是否为链表头）就能移除某个节点，只要写“\\*pp = entry->next”)\nSo there’s lots of pride in doing the small details right. It may not be big and important code, but I do like seeing code where people really thought about the details, and clearly also were thinking about the compiler being able to generate efficient code (rather than hoping that the compiler is so smart that it can make efficient code *despite* the state of the original source code). （纠正细节是令人自豪的事。也许这段代码并非庞大和重要，**但我喜欢看那些注重代码细节的人写的代码，也就是清楚地了解如何才能编译出有效代码**（而不是寄望于聪明的编译器来产生有效代码，即使是那些原始的汇编代码））。\n\n　　Linus举了一个单向链表的例子，但给出的代码太短了，一般的人很难搞明白这两个代码后面的含义。正好，有个编程爱好者阅读了这段话，并给出了一个[比较完整的代码](http://wordaligned.org/articles/two-star-programming)。他的话我就不翻译了，下面给出代码说明。\n　　如果我们需要写一个remove_if(link\\*, rm_cond_func\\*)的函数，也就是传入一个单向链表，和一个自定义的是否删除的函数，然后返回处理后的链接。\n　　这个代码不难，基本上所有的教科书都会提供下面的代码示例，而这种写法也是大公司的面试题标准模板：\n```C\ntypedef struct node\n{\n    struct node * next;\n    ....\n} node;\n\ntypedef bool (* remove_fn)(node const * v);\n\n// Remove all nodes from the supplied list for which the\n// supplied remove function returns true.\n// Returns the new head of the list.\nnode * remove_if(node * head, remove_fn rm)\n{\n    for (node * prev = NULL, * curr = head; curr != NULL; )\n    {\n        node * const next = curr->next;\n        if (rm(curr))\n        {\n            if (prev)\n                prev->next = next;\n            else\n                head = next;\n            free(curr);\n        }\n        else\n            prev = curr;\n        curr = next;\n    }\n    return head;\n}\n```\n　　这里remove_fn由调用查提供的一个是否删除当前实体结点的函数指针，其会判断删除条件是否成立。这段代码维护了两个节点指针prev和curr，**标准的教科书写法——删除当前结点时，需要一个previous的指针，并且还要这里还需要做一个边界条件的判断——curr是否为链表头**。于是，要删除一个节点（不是表头），只要将前一个节点的next指向当前节点的next指向的对象，即下一个节点（即：prev->next = curr->next），然后释放当前节点。\n　　但在Linus看来，这是不懂指针的人的做法。那么，什么是core low-level coding呢？那就是**有效地利用二级指针，将其作为管理和操作链表的首要选项**。代码如下：\n```C\nvoid remove_if(node ** head, remove_fn rm)\n{\n    for (node** curr = head; *curr; )\n    {\n        node * entry = *curr;\n        if (rm(entry))\n        {\n            *curr = entry->next;\n            free(entry);\n        }\n        else\n            curr = &entry->next;\n    }\n}\n```\n<!--more-->\n　　同上一段代码有何改进呢？我们看到：不需要prev指针了，也不需要再去判断是否为链表头了，但是，**curr变成了一个指向指针的指针**。这正是这段程序的精妙之处。（注意，我所highlight的那三行代码）\n让我们来人肉跑一下这个代码，对于——\n* 删除节点是表头的情况，输入参数中传入head的二级指针，在for循环里将其初始化curr，然后entry就是\\*head(\\*curr)，我们马上删除它，那么第8行就等效于\\*head = (\\*head)->next，就是删除表头的实现。\n* 删除节点不是表头的情况，对于上面的代码，我们可以看到：\n\t1. （第12行）如果不删除当前结点 —— curr保存的是当前结点next指针的地址。\n\t2. （第5行） entry 保存了 \\*curr —— 这意味着在下一次循环：entry就是prev->next指针所指向的内存。\n\t3. （第8行）删除结点：\\*curr = entry->next; —— 于是：prev->next 指向了 entry -> next;\n　　是不是很巧妙？我们可以只用一个二级指针来操作链表，对所有节点都一样。\n　　如果你对上面的代码和描述理解上有困难的话，你可以看看下图的示意：\n![delete list](http://7xpwqp.com1.z0.glb.clouddn.com/2014-02-17-01)\n***\n__2016-01-36 更新__\n上面的一段解释是摘抄某个大神的解释，我想各位看的应该是晕晕乎乎的。其实不只是你，我每次隔一段时间再看这篇文章也还是要在想一遍到底是怎么回事。主要是这个示意图并不能很好的说明这个问题的根源。\n个人觉得这段程序并没有比上面用到prev指针的方法简便许多，主要是提供一种二级指针在hack linux中的常见的使用方法。\n二级指针，指向指针的指针，__拥有修改其指向的指针的能力__。这里我们主要看上面代码的第12行。二级指针curr，保存了当前节点entry的后继entry->next这个指针的地址，那么如果我们修改\\*curr，其实就是修改了entry->next这个指针的指向。这样的话，我们就不需要再声明一个prev指针变量，来保存节点前驱的地址，以便在删除当前节点的时候需要用前驱节点修改其后继节点的指向。去掉了prev这个前驱节点指针的变量，我们也就不再需要判断是否为header节点指针了。\n核心思想就是在涉及指针型变量的操作时，用二级指针可以方便的修改指针的指向。\n***\n\n***\n__2014-07-14 更新__　　memcached在删除hash_table中的单向表的某个节点的时候，也使用了二级指针的技术\n```C\nvoid assoc_delete(const char *key, const size_t nkey, const uint32_t hv) {\n    item **before = _hashitem_before(key, nkey, hv);\n\n    if (*before) {\n        item *nxt;\n        hash_items--;\n        /* The DTrace probe cannot be triggered as the last instruction\n         * due to possible tail-optimization by the compiler\n         */\n        MEMCACHED_ASSOC_DELETE(key, nkey, hash_items);\n        nxt = (*before)->h_next;\n        (*before)->h_next = 0;   /* probably pointless, but whatever. */\n        *before = nxt;\n        return;\n    }\n    /* Note:  we never actually get here.  the callers don't delete things\n       they can't find. */\n    assert(*before != 0);\n}\n```\n　　要实现单向列表的删除，按照一般教科书上的方法要声明两个指针，pre、cur，用来保存当前的节点和其前置的节点。但是如果应用二级指针，保存指向当前节点指针的地址\\*\\*before，则\\*before表示指向当前节点的指针，用这个方法可以非常优雅的解决问题。\n***\n","slug":"黑科技-巧用二级指针删除单向链表","published":1,"updated":"2016-01-26T03:29:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfec00030qi5o1enhy68","sticky":0},{"title":"谈谈如何设计秒杀服务","date":"2014-07-26T04:34:10.000Z","_content":"　　上周末去百度参加了一场LBS部门的招聘专场，虽然刚换了工作，但是人力资源美眉盛情邀请，而且是周末也不用请假，本着去学习的心态去试了一下。以前去百度面试过几次，面试官给人的感觉还是很nice的，虽然不会像很多外企的面试官会闲到给你讲课，但是会和你一起讨论面试的问题，共同的提高。\n　　百度招聘，区别于360等新兴创业型公司，更偏重于工程师的设计技能和思维方法。百度招聘不会深入的考察工程师所用语言的特性，陷阱等问题，而更关注考察基本的数据结构算法及其在实际例子中的应用。\n　　一面还是偏向考察基本数据结构的掌握的，问了一些诸如跳跃表的实现，快速排序和堆排序，并发程序的数据同步问题等，现场写了一个单向链表递归反转的函数。\n　　二面就是偏向考察思维方法了，因为知道我是新浪过来的，问了一个怎样设计一个大V粉丝TOP10排名的服务。另外一个印象比较深的问题就是如何实现秒杀的服务。\n　　这里主要想和大家聊聊秒杀服务的实现方法。\n　　秒杀服务在日常的互联网生活中非常常见，广告心理学曾近分析过，人们对于免费、低价等字眼的抵抗力往往非常低，所以秒杀是一种成本低廉又行之有效的营销方式。\n　　当然，从技术上来讲，秒杀对于后端服务同时也是一场噩梦。试想，如果前期宣传工作做得完备，数百万的用户守护在各种终端旁，在同一时刻进行请求，这个流量的峰值将会多么的可怕。\n<!--more-->\n　　一个公平的秒杀，会要求请求时间排名靠前的用户会确实的可以进行后续支付等操作，并成功买到秒杀的物品。所卖出的秒杀物品比计划不会多一个也不会少一个。\n　　因为当时面试的时间比较紧，思路不是很清晰，想了一个取巧的方案。将秒杀的过程分为几个阶段，如点击秒杀，填单，支付等，秒杀这一层只是进行一个大概的人数筛选，比如100个物品的秒杀，接口可以设计为允许1000人左右提交，之后就关闭点击秒杀的接口。在填单和支付的时再根据点击秒杀的排名信息确定是否支付成功。但是这种实现方法的缺陷是有一部分用户秒杀请求成功提交，支付步奏失败了，对这部分用户的用户体验不够好。\n　　回去之后仔细想了想，其实还有更好得解决方案。可以在提交秒杀请求的时候就确定能不能成功。这个接口需要设计为接收所有秒杀的请求，并在存储中记录一条秒杀记录，如ID，用户名，秒杀提交时间等。提交之后接口会有一个小的延迟，在这个延迟内，后端会有一个离线服务对秒杀的存储数据进行一个整理排名过滤等操作，确实的选出能支付成功的用户列表。秒杀服务在延迟时间后会查询存储的购买列表，看看这个提交的ID在不在秒杀成功的列表中，从而决定是否进行后续的步奏。\n![miaosha](http://7xpwqp.com1.z0.glb.clouddn.com/2014-07-26-01.png)\n　　在上一家公司一直也做过秒杀的服务，这也是个遗憾吧，在这里随便谈谈我的想法，还望高手指正~\n","source":"_posts/谈谈如何设计秒杀服务.md","raw":"title: 谈谈如何设计秒杀服务\ndate: 2014-07-26 12:34:10\ntags: [架构, 面试]\n---\n　　上周末去百度参加了一场LBS部门的招聘专场，虽然刚换了工作，但是人力资源美眉盛情邀请，而且是周末也不用请假，本着去学习的心态去试了一下。以前去百度面试过几次，面试官给人的感觉还是很nice的，虽然不会像很多外企的面试官会闲到给你讲课，但是会和你一起讨论面试的问题，共同的提高。\n　　百度招聘，区别于360等新兴创业型公司，更偏重于工程师的设计技能和思维方法。百度招聘不会深入的考察工程师所用语言的特性，陷阱等问题，而更关注考察基本的数据结构算法及其在实际例子中的应用。\n　　一面还是偏向考察基本数据结构的掌握的，问了一些诸如跳跃表的实现，快速排序和堆排序，并发程序的数据同步问题等，现场写了一个单向链表递归反转的函数。\n　　二面就是偏向考察思维方法了，因为知道我是新浪过来的，问了一个怎样设计一个大V粉丝TOP10排名的服务。另外一个印象比较深的问题就是如何实现秒杀的服务。\n　　这里主要想和大家聊聊秒杀服务的实现方法。\n　　秒杀服务在日常的互联网生活中非常常见，广告心理学曾近分析过，人们对于免费、低价等字眼的抵抗力往往非常低，所以秒杀是一种成本低廉又行之有效的营销方式。\n　　当然，从技术上来讲，秒杀对于后端服务同时也是一场噩梦。试想，如果前期宣传工作做得完备，数百万的用户守护在各种终端旁，在同一时刻进行请求，这个流量的峰值将会多么的可怕。\n<!--more-->\n　　一个公平的秒杀，会要求请求时间排名靠前的用户会确实的可以进行后续支付等操作，并成功买到秒杀的物品。所卖出的秒杀物品比计划不会多一个也不会少一个。\n　　因为当时面试的时间比较紧，思路不是很清晰，想了一个取巧的方案。将秒杀的过程分为几个阶段，如点击秒杀，填单，支付等，秒杀这一层只是进行一个大概的人数筛选，比如100个物品的秒杀，接口可以设计为允许1000人左右提交，之后就关闭点击秒杀的接口。在填单和支付的时再根据点击秒杀的排名信息确定是否支付成功。但是这种实现方法的缺陷是有一部分用户秒杀请求成功提交，支付步奏失败了，对这部分用户的用户体验不够好。\n　　回去之后仔细想了想，其实还有更好得解决方案。可以在提交秒杀请求的时候就确定能不能成功。这个接口需要设计为接收所有秒杀的请求，并在存储中记录一条秒杀记录，如ID，用户名，秒杀提交时间等。提交之后接口会有一个小的延迟，在这个延迟内，后端会有一个离线服务对秒杀的存储数据进行一个整理排名过滤等操作，确实的选出能支付成功的用户列表。秒杀服务在延迟时间后会查询存储的购买列表，看看这个提交的ID在不在秒杀成功的列表中，从而决定是否进行后续的步奏。\n![miaosha](http://7xpwqp.com1.z0.glb.clouddn.com/2014-07-26-01.png)\n　　在上一家公司一直也做过秒杀的服务，这也是个遗憾吧，在这里随便谈谈我的想法，还望高手指正~\n","slug":"谈谈如何设计秒杀服务","published":1,"updated":"2016-01-25T10:44:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfem000a0qi50aqynbzy","sticky":0},{"title":"当黑客马拉松遇上全栈工程师","date":"2015-04-20T06:05:22.000Z","_content":"&emsp;&emsp;4月17号参加了新浪微博平台架构组织的HackAthon24小时黑客马拉松活动。想想还是第一次参加这一类的技术活动，心情上感觉新奇又激情。其实感觉后端工程师在这种创新类比赛上优势不明显，幸遇@赵青-Q不嫌弃，热情的接纳了我，终于有机会得以参赛。\n\n![all member](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-01.jpg)\n\n&emsp;&emsp;曾经听前辈们闲聊的时候提到过，黑客马拉松应该是起源于FaceBook的一些小活动。每到了周五的下午，开发任务不忙的工程师们会聚在一起，先喝一点啤酒，吃一点小零食，把自己搞high一些，然后大家开始头脑风暴，畅所欲言，吐槽别人的代码，吐槽公司某些项目的架构，并可以随意向其他人的代码或者架构提出挑战，拿出自己认为合适的方案甚至是实现，展现出一种异常开放的技术氛围。必定的，这种routine，这种开放的讨论激烈的碰撞对于提升公司项目的架构及代码质量以及对于工程师自身水平的提高都是非常有帮助的。后来，慢慢的演变成为一种活动，在规定的24小时内，工程师们组队完成一个独立的项目，可以是和公司的业务完全没有关系的，纯粹只是为了实现自己心中的想象力。这个活动将工程师从日常繁重的开发任务中解放出来，应用一些日常工作中用不到的技术，实现一些好玩有趣的事情。\n<!--more-->\n&emsp;&emsp;所以，我们comos小队这次参赛的项目“a living tree”，正式基于这个目的来选择的。除了通哥@天枫皓月外，我和bigbigant@赵青-Q都不是专业的前端工程师，而且我们部门前端的开发工作中用也不可能有机会用到“a living tree”中应用的2d引擎cocos2d-js。在参赛前的一周由于部门工作的进度很紧张，也完全没有时间和机会进行提前的准备工作。以致于在参赛当天才现场看cocos2d-js的官方文档（而且文档还很shi），现场向通哥请教js的语法等相关问题，现场踩js中诸如date对象month从0计数这样的坑。。。前半段的开发还是很欢乐的，进度同样也是相当缓慢，以致于本来计划搞到12点左右就去酒店开个小时房睡一会儿的，结果最后真的是一刻都没有睡，一直在代码中。虽然自己已经是快步入三十而立的中年大叔的行列，但是发现自己体力还行，还可以和刚毕业的小鲜肉们一起拼一拼~\n\n![living tree boot photo](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-02.png)\n\n&emsp;&emsp;“a living tree”是用js引擎cocos2d-js实现的一个H5的养成类小游戏，在一个虚拟世界里属于自己的一棵完全个性的树。试想一棵树从发芽开始，根据真实的历史天气数据的因素进行发芽，生长，开花，落叶等。为了能完全展现天气与季节的变化，树的成长等，我们思考并设计了许多算法，这里就不再赘述了，详细的介绍可以参看<http://blog.sina.com.cn/s/blog_794d4b390102vmjn.html>。最后演示的时候还是大致完成了我们开始时的设想。\n&emsp;&emsp;其实，我想通过这次比赛，引申的聊一聊前一段时间在技术圈非常火的“全栈工程师”的概念。有的人认为，“全栈工程师”就是万恶的资本主义进一步剥削可怜的劳动码农的一种方式，让一个工程师做了前端，后端，测试，设计等等的应该细分为几个人的工作，当然这样说其实是个玩笑话。然而，在日益分工精细化的现今社会，“全栈工程师”确实是得到了许多人的质疑。但是，从实际的例子来看，在像FaceBook这样的新兴互联网公司中，项目的人员组成趋向于几个人的小团队，工程师的职责也不仅仅是编码一样，有别于微软这一类的公司，不会一个项目动不动配一个50人的独立测试部门之类的。类似于小团队的这种项目组织方式在实际工作中确实是表现的非常高效的。原因又是为什么呢？\n\n![hackers](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-03.jpg)\n\n&emsp;&emsp;一般我们技术的同学在印名片的时候可能会常见两类title。一类是Programmer，另一类是Engineer。虽然普遍的感觉这两类Title在工作性质上没有本质区别，但是我觉得还是略有不同的。Programmer编码者。是面向代码工作的，只为代码负责，不会对出编码以外的事情关心，如需求的正确与否，测试，以及持续集成等。而Engineer是面向问题工作的，会为了解决任何与项目相关的问题而工作，不止是关心代码写的是否高质美观，还会配有详尽的文档，适当的培训以及便于集成测试的贴心小工具，甚至会学习与业务相关的知识，以便能更好的理解需求以及对需求提出建设性的意见。\n&emsp;&emsp;一个面向问题而工作的工程师不会因为一个新技术能快速解决当前的问题而不去学习并使用他的，一个面向问题而工作的工程师不会因为要分清自己是前端还是后端而不去尝试了解其他领域的技术基础知识。反观我在日常工作中的状态，也许不仅仅是我自己，也是大多数后端工程师的通病。可能会有一点觉得前端的工作比较浅显，而后端的工作才是高大上的。但是听过通哥几次前端技术的培训，了解到目前智能机，多终端等前端技术日新月异的发展，现今许多以前我们认为很浅显没什么干货的领域已经不是原来我们认为的那个样子了，都在随着时代的发展不断的演进变化中。\n&emsp;&emsp;因为我也是有一定代码洁癖的人，过去的代码确实也被各位主管和领导抬爱，认可，自认为已经可以写出符合工业领域应用要求的代码。但是其实大多数都是在安静的环境，没有人过度催促及时间不紧张的进度，充分的对所使用工具的理解，最后在历经多个迭代历经打磨之后完成的。然后，就像一个功夫高手上了到了战场一样，没有了平时演武中心平气和一刀一式的切玉劲，一个照面，一颗头就下来了，你过去所积累下来的习惯是否会成为你生存下去的桎梏呢？同样的，在限定24小时的黑客马拉松中，没有了条件让你心平气和的设计架构，没有了机会让你充分熟悉你所使用的工具，没有了时间让你慢慢的debug，甚至再抛开了常用的顺手工具，抛开了自己的电脑，自问我是否还能写出一份自己看的过去的完美代码吗？\n&emsp;&emsp;一个人，如果认定了要在技术的道路上走下去，那么就需要不断的前行，持续更新自己的知识体系。随着阅历的成长，经验会不断的累计，但是相应的也会更加的守旧，这也许是自然的必然规律，想想我们年轻的时候是怎么看那些老前辈的吧~所以要善于能打破自己为自己设置的壁垒，更加开放性的拥抱新技术、新事物，尝试与新锐的工程师进行沟通。这大概这才是一个即将步入中年的工程师最重要的修行吧。\n","source":"_posts/当黑客马拉松遇上全栈工程师.md","raw":"title: 当黑客马拉松遇上全栈工程师\ndate: 2015-04-20 14:05:22\ntags: [感悟]\n---\n&emsp;&emsp;4月17号参加了新浪微博平台架构组织的HackAthon24小时黑客马拉松活动。想想还是第一次参加这一类的技术活动，心情上感觉新奇又激情。其实感觉后端工程师在这种创新类比赛上优势不明显，幸遇@赵青-Q不嫌弃，热情的接纳了我，终于有机会得以参赛。\n\n![all member](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-01.jpg)\n\n&emsp;&emsp;曾经听前辈们闲聊的时候提到过，黑客马拉松应该是起源于FaceBook的一些小活动。每到了周五的下午，开发任务不忙的工程师们会聚在一起，先喝一点啤酒，吃一点小零食，把自己搞high一些，然后大家开始头脑风暴，畅所欲言，吐槽别人的代码，吐槽公司某些项目的架构，并可以随意向其他人的代码或者架构提出挑战，拿出自己认为合适的方案甚至是实现，展现出一种异常开放的技术氛围。必定的，这种routine，这种开放的讨论激烈的碰撞对于提升公司项目的架构及代码质量以及对于工程师自身水平的提高都是非常有帮助的。后来，慢慢的演变成为一种活动，在规定的24小时内，工程师们组队完成一个独立的项目，可以是和公司的业务完全没有关系的，纯粹只是为了实现自己心中的想象力。这个活动将工程师从日常繁重的开发任务中解放出来，应用一些日常工作中用不到的技术，实现一些好玩有趣的事情。\n<!--more-->\n&emsp;&emsp;所以，我们comos小队这次参赛的项目“a living tree”，正式基于这个目的来选择的。除了通哥@天枫皓月外，我和bigbigant@赵青-Q都不是专业的前端工程师，而且我们部门前端的开发工作中用也不可能有机会用到“a living tree”中应用的2d引擎cocos2d-js。在参赛前的一周由于部门工作的进度很紧张，也完全没有时间和机会进行提前的准备工作。以致于在参赛当天才现场看cocos2d-js的官方文档（而且文档还很shi），现场向通哥请教js的语法等相关问题，现场踩js中诸如date对象month从0计数这样的坑。。。前半段的开发还是很欢乐的，进度同样也是相当缓慢，以致于本来计划搞到12点左右就去酒店开个小时房睡一会儿的，结果最后真的是一刻都没有睡，一直在代码中。虽然自己已经是快步入三十而立的中年大叔的行列，但是发现自己体力还行，还可以和刚毕业的小鲜肉们一起拼一拼~\n\n![living tree boot photo](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-02.png)\n\n&emsp;&emsp;“a living tree”是用js引擎cocos2d-js实现的一个H5的养成类小游戏，在一个虚拟世界里属于自己的一棵完全个性的树。试想一棵树从发芽开始，根据真实的历史天气数据的因素进行发芽，生长，开花，落叶等。为了能完全展现天气与季节的变化，树的成长等，我们思考并设计了许多算法，这里就不再赘述了，详细的介绍可以参看<http://blog.sina.com.cn/s/blog_794d4b390102vmjn.html>。最后演示的时候还是大致完成了我们开始时的设想。\n&emsp;&emsp;其实，我想通过这次比赛，引申的聊一聊前一段时间在技术圈非常火的“全栈工程师”的概念。有的人认为，“全栈工程师”就是万恶的资本主义进一步剥削可怜的劳动码农的一种方式，让一个工程师做了前端，后端，测试，设计等等的应该细分为几个人的工作，当然这样说其实是个玩笑话。然而，在日益分工精细化的现今社会，“全栈工程师”确实是得到了许多人的质疑。但是，从实际的例子来看，在像FaceBook这样的新兴互联网公司中，项目的人员组成趋向于几个人的小团队，工程师的职责也不仅仅是编码一样，有别于微软这一类的公司，不会一个项目动不动配一个50人的独立测试部门之类的。类似于小团队的这种项目组织方式在实际工作中确实是表现的非常高效的。原因又是为什么呢？\n\n![hackers](http://7xpwqp.com1.z0.glb.clouddn.com/2014%2F04%2F20-03.jpg)\n\n&emsp;&emsp;一般我们技术的同学在印名片的时候可能会常见两类title。一类是Programmer，另一类是Engineer。虽然普遍的感觉这两类Title在工作性质上没有本质区别，但是我觉得还是略有不同的。Programmer编码者。是面向代码工作的，只为代码负责，不会对出编码以外的事情关心，如需求的正确与否，测试，以及持续集成等。而Engineer是面向问题工作的，会为了解决任何与项目相关的问题而工作，不止是关心代码写的是否高质美观，还会配有详尽的文档，适当的培训以及便于集成测试的贴心小工具，甚至会学习与业务相关的知识，以便能更好的理解需求以及对需求提出建设性的意见。\n&emsp;&emsp;一个面向问题而工作的工程师不会因为一个新技术能快速解决当前的问题而不去学习并使用他的，一个面向问题而工作的工程师不会因为要分清自己是前端还是后端而不去尝试了解其他领域的技术基础知识。反观我在日常工作中的状态，也许不仅仅是我自己，也是大多数后端工程师的通病。可能会有一点觉得前端的工作比较浅显，而后端的工作才是高大上的。但是听过通哥几次前端技术的培训，了解到目前智能机，多终端等前端技术日新月异的发展，现今许多以前我们认为很浅显没什么干货的领域已经不是原来我们认为的那个样子了，都在随着时代的发展不断的演进变化中。\n&emsp;&emsp;因为我也是有一定代码洁癖的人，过去的代码确实也被各位主管和领导抬爱，认可，自认为已经可以写出符合工业领域应用要求的代码。但是其实大多数都是在安静的环境，没有人过度催促及时间不紧张的进度，充分的对所使用工具的理解，最后在历经多个迭代历经打磨之后完成的。然后，就像一个功夫高手上了到了战场一样，没有了平时演武中心平气和一刀一式的切玉劲，一个照面，一颗头就下来了，你过去所积累下来的习惯是否会成为你生存下去的桎梏呢？同样的，在限定24小时的黑客马拉松中，没有了条件让你心平气和的设计架构，没有了机会让你充分熟悉你所使用的工具，没有了时间让你慢慢的debug，甚至再抛开了常用的顺手工具，抛开了自己的电脑，自问我是否还能写出一份自己看的过去的完美代码吗？\n&emsp;&emsp;一个人，如果认定了要在技术的道路上走下去，那么就需要不断的前行，持续更新自己的知识体系。随着阅历的成长，经验会不断的累计，但是相应的也会更加的守旧，这也许是自然的必然规律，想想我们年轻的时候是怎么看那些老前辈的吧~所以要善于能打破自己为自己设置的壁垒，更加开放性的拥抱新技术、新事物，尝试与新锐的工程师进行沟通。这大概这才是一个即将步入中年的工程师最重要的修行吧。\n","slug":"当黑客马拉松遇上全栈工程师","published":1,"updated":"2016-01-20T03:25:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfeq000f0qi5wt9q1jnt","sticky":0},{"title":"多线程C调用python api的陷阱","date":"2015-01-06T03:45:22.000Z","_content":"　　众所周知，用脚本语言编写的服务（wsgi接口）都需要一个server容器，常见的如php的php-fpm, lightd等。python中一般是用的uwsgi，uwsgi是在wsgi的基础上的一种新的协议，可以用来部署python等脚本程序的运行。然而在不熟悉uwsgi的代码架构和c调用python的api情况下进行开发可能会遇到一些意想不到的问题。\n<!--more-->\n　　我们先看一段代码，下面这段代码是用的Flask框架，每次请求的时候会把COUNT的值先减一再加一，最后再乘二。如果请求50次，其最终的结果应该是2的50次幂。\n```Python\nfrom flask import Flask, request\n\nCOUNT = 1 \n\napp = Flask(__name__)\n\n\n@app.route('/test_uwsgi')\ndef index():\n    global COUNT\n    COUNT=COUNT-1\n    COUNT=COUNT+1\n    COUNT=COUNT*2\n    print COUNT\n    return 'OK'\n```\n```Bash\n17179869184\n34359738368\n68719476736\n137438953472\n274877906944\n549755813888\n1099511627776\n2199023255552\n4398046511104\n8796093022208\n17592186044416\n35184372088832\n70368744177664\n140737488355328\n281474976710656\n562949953421312\n1125899906842624\n```\n这是直接执行50次index函数得到的最后几行的结果，可得结果为2的50次幂。\n```Bash\n536870912\n1073741824\n2147483648\n4294967296\n8589934592\n17179869184\n34359738368\n68719476736\n137438953472\n274877906944\n549755813888\n1099511627776\n2199023255552\n4398046511104\n8796093022208\n17592186044416\n35184372088832\n70368744177664\n140737488355328\n281474976710656\n5629499534213121125899906842624\n```\n　　这是通过ab测试，用多个并发访问/test_uwsgi接口50次得到的最后几行的结果。可以看出最终的结果肯定是个异常数字。为什么程序在uwsgi中运行时的运行结果会出现异常呢？\n　　其实大家通过阅读这个简单的例子就可以发现，这种例子一般都是用来演示多线程共享数据同步问题的时候，如果不加锁会暴露问题的例子。下面的代码我们就在修改共享资源COUNT的时候加上互斥锁，看看有没有什么变化。\n```Python\nfrom flask import Flask, request\nimport threading\n\nmutex = threading.Lock()\nCOUNT = 1 \n\napp = Flask(__name__)\n\n\n@app.route('/test_uwsgi')\ndef index():\n    global COUNT\n    global mutex\n    mutex.acquire()\n    COUNT=COUNT-1\n    COUNT=COUNT+1\n    COUNT=COUNT*2\n    print COUNT\n    mutex.release()\n    return 'OK'\n```\n　　上面的代码也是放到uwsgi的容器里面运行，通过http接口多个并发访问50次，得到的结果是正确的。但是这是为什么呢？在我们原来的python代码中并没有写任何涉及多进程的操作，虽然uwsgi在配置文件中开启了多个线程可以并发的处理请求，但是按笔者原来的理解，不是应该每个线程执行自己独立的Python解释器吗？每个线程在运行python脚本的时候的数据不应该是隔离的吗？\n　　为了弄明白上面的问题，我们不得不研究研究uwsgi及其server架构中的结构和设计。\n　　UWSGI是在python中广泛使用的一个服务器应用容器，类似于php上常见的wsgi协议的服务器应用容器，如mod-php、php-fpm、lightd等。uwsgi协议是在原有的wsgi协议之上新增了一套uwsgi的协议。\n![uwsgi server proto](http://7xpwqp.com1.z0.glb.clouddn.com/2015-01-07-01.png)\n　　通过研读uwsgi的源码（core/uwsgi.c core/loop.c core/init.c core/master_util.c core/util.c），可以知道uwsgi的server设计，采用的是UNX书中介绍归纳的服务器程序设计范式8，暨TCP预先创建线程服务器程序，每个线程各自accept。\n```C\nint main(int argc, char *argv[], char *envp[]) {\n    uwsgi_setup(argc, argv, envp);\n    return uwsgi_run();\n}\n\nvoid uwsgi_setup(int argc, char *argv[], char *envp[]) {\n\n    int i;\n\n    struct utsname uuts;\n\n    ......\n\n    ...设置和初始化各种资源，这里就省略了，有兴趣的自己看看\n    \n    ......\n\n    //最主要的是这行\n    uwsgi_start((void *) uwsgi.argv);\n}\n\nint uwsgi_start(void *v_argv) {\n\n    ......\n\n    简化摘要一些主要的代码\n\n    ......\n\n    ... 题外话，这里是创建一个多线程的共享内存空间，后面uwsgi_setup_workers的时候会用到。\n        因为uwsgi有一个master进程，可以监测各个子进程的状态，所以需要一块匿名共享内存\n    // initialize sharedareas\n    uwsgi_sharedareas_init();\n\n    // setup queue\n    if (uwsgi.queue_size > 0) {\n        uwsgi_init_queue();\n    }\n\n    ... 这里很重要，uwsgi.p是一个接口，uwsgi中部署的app在这里初始化（在uwsgi中，部署的APP需要所对应语言的插件，如python就用python插件）\n        后面也会看到，实际上uwsgi所执行的python代码，其所有模块的import都在这里执行\n    // initialize request plugin only if workers or master are available\n    if (uwsgi.sockets || uwsgi.master_process || uwsgi.no_server || uwsgi.command_mode || uwsgi.loop) {\n        for (i = 0; i < 256; i++) {\n            if (uwsgi.p[i]->init) {\n                uwsgi.p[i]->init();\n            }\n        }\n    }\n\n    // again check for workers/sockets...\n    if (uwsgi.sockets || uwsgi.master_process || uwsgi.no_server || uwsgi.command_mode || uwsgi.loop) {\n        for (i = 0; i < 256; i++) {\n            if (uwsgi.p[i]->post_init) {\n                uwsgi.p[i]->post_init();\n            }\n        }\n    }\n\n    。。。这里主要是设置各个worker的共享内存空间\n    // initialize workers/master shared memory segments\n    uwsgi_setup_workers();\n\n    // here we spawn the workers...\n    if (!uwsgi.status.is_cheap) {\n        if (uwsgi.cheaper && uwsgi.cheaper_count) {\n            int nproc = uwsgi.cheaper_initial;\n            if (!nproc)\n                nproc = uwsgi.cheaper_count;\n            for (i = 1; i <= uwsgi.numproc; i++) {\n                if (i <= nproc) {\n                    if (uwsgi_respawn_worker(i))\n                        break;\n                    uwsgi.respawn_delta = uwsgi_now();\n                }\n                else {\n                    uwsgi.workers[i].cheaped = 1;\n                }\n            }\n        }\n        else {\n            for (i = 2 - uwsgi.master_process; i < uwsgi.numproc + 1; i++) {\n                。。。这里就是根据我们设置的进程数，去fork子进程\n                if (uwsgi_respawn_worker(i))\n                    break;\n                uwsgi.respawn_delta = uwsgi_now();\n            }\n        }\n    }\n\n\n    // END OF INITIALIZATION\n    return 0;\n\n}\n\nint uwsgi_respawn_worker(int wid) {\n\n    。。。主要是这行代码，fork子进程，里面就不跟了\n    pid_t pid = uwsgi_fork(uwsgi.workers[wid].name);\n\n    if (pid == 0) {\n        signal(SIGWINCH, worker_wakeup);\n        signal(SIGTSTP, worker_wakeup);\n        uwsgi.mywid = wid;\n        uwsgi.mypid = getpid();\n        // pid is updated by the master\n        //uwsgi.workers[uwsgi.mywid].pid = uwsgi.mypid;\n        // OVERENGINEERING (just to be safe)\n        uwsgi.workers[uwsgi.mywid].id = uwsgi.mywid;\n        /*\n           uwsgi.workers[uwsgi.mywid].harakiri = 0;\n           uwsgi.workers[uwsgi.mywid].user_harakiri = 0;\n           uwsgi.workers[uwsgi.mywid].rss_size = 0;\n           uwsgi.workers[uwsgi.mywid].vsz_size = 0;\n         */\n        // do not reset worker counters on reload !!!\n        //uwsgi.workers[uwsgi.mywid].requests = 0;\n        // ...but maintain a delta counter (yes this is racy in multithread)\n        //uwsgi.workers[uwsgi.mywid].delta_requests = 0;\n        //uwsgi.workers[uwsgi.mywid].failed_requests = 0;\n        //uwsgi.workers[uwsgi.mywid].respawn_count++;\n        //uwsgi.workers[uwsgi.mywid].last_spawn = uwsgi.current_time;\n\n    }\n    else if (pid < 1) {\n        uwsgi_error(\"fork()\");\n    }\n    else {\n        // the pid is set only in the master, as the worker should never use it\n        uwsgi.workers[wid].pid = pid;\n\n        if (respawns > 0) {\n            uwsgi_log(\"Respawned uWSGI worker %d (new pid: %d)\\n\", wid, (int) pid);\n        }\n        else {\n            uwsgi_log(\"spawned uWSGI worker %d (pid: %d, cores: %d)\\n\", wid, pid, uwsgi.cores);\n        }\n    }\n\n    return 0;\n}\n\nint uwsgi_run() {\n\n    。。。也是捡重要的摘抄一些\n        如果pid是master，就执行master_loop\n        如果pid是worker，就执行uwsgi_worker_run\n\n    // !!! from now on, we could be in the master or in a worker !!!\n    if (getpid() == masterpid && uwsgi.master_process == 1) {\n        (void) master_loop(uwsgi.argv, uwsgi.environ);\n    }\n\n    //from now on the process is a real worker\n    uwsgi_worker_run();\n    // never here\n    _exit(0);\n\n}\n\nvoid uwsgi_worker_run() {\n\n    int i;\n\n    if (uwsgi.lazy || uwsgi.lazy_apps) {\n        uwsgi_init_all_apps();\n    }\n\n    uwsgi_ignition();\n\n    // never here\n    exit(0);\n\n}\n\nvoid uwsgi_ignition() {\n\n    if (uwsgi.loop) {\n        void (*u_loop) (void) = uwsgi_get_loop(uwsgi.loop);\n        if (!u_loop) {\n            uwsgi_log(\"unavailable loop engine !!!\\n\");\n            exit(1);\n        }\n        if (uwsgi.mywid == 1) {\n            uwsgi_log(\"*** running %s loop engine [addr:%p] ***\\n\", uwsgi.loop, u_loop);\n        }\n        u_loop();\n        uwsgi_log(\"your loop engine died. R.I.P.\\n\");\n    }\n    else {\n        。。。子进程的循环体，一般是用simple_loop\n        if (uwsgi.async < 1) {\n            simple_loop();\n        }\n        else {\n            async_loop();\n        }\n    }\n\n    // end of the process...\n    end_me(0);\n}\n\n\n。。。一直到这里，在子进程的loop里面才开始创建接收处理request请求的线程\n    线程的执行函数simple_loop_run也是一个循环，基本上都是常规步奏，accept，receive, response...，后面就不继续追下去了\n    在reciev接到请求的数据后，会通过python_call的方法调用python脚本的wsgi函数，处理这个请求\nvoid simple_loop() {\n    uwsgi_loop_cores_run(simple_loop_run);\n}\n\nvoid uwsgi_loop_cores_run(void *(*func) (void *)) {\n    int i;\n    for (i = 1; i < uwsgi.threads; i++) {\n        long j = i;\n        pthread_create(&uwsgi.workers[uwsgi.mywid].cores[i].thread_id, &uwsgi.threads_attr, func, (void *) j);\n    }\n    long y = 0;\n    func((void *) y);\n}\n```\n　　简单来说，就是uwsgi中执行python脚本和直接运行python脚本是不同的。uwsgi执行python脚本是通过调用python c api的方法，首先通过调用api载入python脚本中的module，这时候，像最开始的实例代码一样module import中的相关代码会被执行，所有的全局变量在进程中被创建和初始化。然后uwsgi创建线程，开始处理请求调用python api（python_call），执行python脚本中处理请求的函数（wsgi接口），因为module import在线程创建之前已经执行了，所以之前在进程中的共享数据在线程中是可以访问的。这里就是需要我们着重注意的，在访问这些线程间共享数据的时候需要加锁，或者在编写python脚本的时候尽量少用全局变量而多用单例模式，避免不必要的采坑。\n　　其实上面所述只是对我遇到问题的一个简化，为了帮助大家弄明白uwsgi多线程执行python wsgi接口的相关问题。我所遇到的问题是在处理请求的函数中，调用了一个在全局中创建的gearman client，这个client库不是线程安全的，使用中也没有加锁。当请求的并发比较大的时候，gearman client这个库就会报出一些连接的异常。\n　　由于GIL的存在，Python的多线程并不能充分的利用多核的优势。在实际项目中，我们常常使用多进程来取代多线程的方法，来实现一些需要并发的业务。然而，进程的开销毕竟比较大，并且设计进程间的数据同步，进程间通信等操作相对线程来说十分的复杂，也是开发中的一个痛点，我们经常为了性能而放弃使用python转而使用c多线程的方案，但是确实降低了代码的可维护性，增加了代码的成本。\n　　在了解了uwsgi的多线程结构之后，其实我们也可以学习其通过多线程调用python c api的方法，使用c的线程调用python的业务代码，将需要共享的数据放在c线程创建之前进行module import。将c多线程的部分提取出来成为一个框架，工程师只需要书写python的业务代码并在注意在使用共享数据的时候加锁。框架部分交由专业的有经验的c/python工程师进行维护，这样在不牺牲代码生产效率的前提下，提升了程序的性能。\n　　后记：其实这个问题并不是十分的复杂，暴露的问题是对于uwsgi的代码结构，和python c api以及c调用python的方法和相关概念等不是非常的熟练，暴露了自己知识体系中的短板。由于那几天同时在开发几个需求，没有对问题进行详细的测试，没有仔细的分析和查找Trackback中的错误，反而是一直在怀疑被调用方的接口性能问题。其实这个团队在交流上确实也存在一些问题，争论基本上靠喊，靠抢话，不是就是论事而是经常人身攻击。每当有工程师的方案确实在理，确实证明是可用的时候，反对的人也宁死不妥协。。。这大概就是像新浪这样臃肿老旧缺少活力的大公司的通病吧（一点吐槽，熟人请无视）。\n","source":"_posts/多线程C调用python-api的陷阱.md","raw":"title: 多线程C调用python api的陷阱\ndate: 2015-01-06 11:45:22\ntags: [uwsgi, 多线程, Python C API, C调用Python]\n---\n　　众所周知，用脚本语言编写的服务（wsgi接口）都需要一个server容器，常见的如php的php-fpm, lightd等。python中一般是用的uwsgi，uwsgi是在wsgi的基础上的一种新的协议，可以用来部署python等脚本程序的运行。然而在不熟悉uwsgi的代码架构和c调用python的api情况下进行开发可能会遇到一些意想不到的问题。\n<!--more-->\n　　我们先看一段代码，下面这段代码是用的Flask框架，每次请求的时候会把COUNT的值先减一再加一，最后再乘二。如果请求50次，其最终的结果应该是2的50次幂。\n```Python\nfrom flask import Flask, request\n\nCOUNT = 1 \n\napp = Flask(__name__)\n\n\n@app.route('/test_uwsgi')\ndef index():\n    global COUNT\n    COUNT=COUNT-1\n    COUNT=COUNT+1\n    COUNT=COUNT*2\n    print COUNT\n    return 'OK'\n```\n```Bash\n17179869184\n34359738368\n68719476736\n137438953472\n274877906944\n549755813888\n1099511627776\n2199023255552\n4398046511104\n8796093022208\n17592186044416\n35184372088832\n70368744177664\n140737488355328\n281474976710656\n562949953421312\n1125899906842624\n```\n这是直接执行50次index函数得到的最后几行的结果，可得结果为2的50次幂。\n```Bash\n536870912\n1073741824\n2147483648\n4294967296\n8589934592\n17179869184\n34359738368\n68719476736\n137438953472\n274877906944\n549755813888\n1099511627776\n2199023255552\n4398046511104\n8796093022208\n17592186044416\n35184372088832\n70368744177664\n140737488355328\n281474976710656\n5629499534213121125899906842624\n```\n　　这是通过ab测试，用多个并发访问/test_uwsgi接口50次得到的最后几行的结果。可以看出最终的结果肯定是个异常数字。为什么程序在uwsgi中运行时的运行结果会出现异常呢？\n　　其实大家通过阅读这个简单的例子就可以发现，这种例子一般都是用来演示多线程共享数据同步问题的时候，如果不加锁会暴露问题的例子。下面的代码我们就在修改共享资源COUNT的时候加上互斥锁，看看有没有什么变化。\n```Python\nfrom flask import Flask, request\nimport threading\n\nmutex = threading.Lock()\nCOUNT = 1 \n\napp = Flask(__name__)\n\n\n@app.route('/test_uwsgi')\ndef index():\n    global COUNT\n    global mutex\n    mutex.acquire()\n    COUNT=COUNT-1\n    COUNT=COUNT+1\n    COUNT=COUNT*2\n    print COUNT\n    mutex.release()\n    return 'OK'\n```\n　　上面的代码也是放到uwsgi的容器里面运行，通过http接口多个并发访问50次，得到的结果是正确的。但是这是为什么呢？在我们原来的python代码中并没有写任何涉及多进程的操作，虽然uwsgi在配置文件中开启了多个线程可以并发的处理请求，但是按笔者原来的理解，不是应该每个线程执行自己独立的Python解释器吗？每个线程在运行python脚本的时候的数据不应该是隔离的吗？\n　　为了弄明白上面的问题，我们不得不研究研究uwsgi及其server架构中的结构和设计。\n　　UWSGI是在python中广泛使用的一个服务器应用容器，类似于php上常见的wsgi协议的服务器应用容器，如mod-php、php-fpm、lightd等。uwsgi协议是在原有的wsgi协议之上新增了一套uwsgi的协议。\n![uwsgi server proto](http://7xpwqp.com1.z0.glb.clouddn.com/2015-01-07-01.png)\n　　通过研读uwsgi的源码（core/uwsgi.c core/loop.c core/init.c core/master_util.c core/util.c），可以知道uwsgi的server设计，采用的是UNX书中介绍归纳的服务器程序设计范式8，暨TCP预先创建线程服务器程序，每个线程各自accept。\n```C\nint main(int argc, char *argv[], char *envp[]) {\n    uwsgi_setup(argc, argv, envp);\n    return uwsgi_run();\n}\n\nvoid uwsgi_setup(int argc, char *argv[], char *envp[]) {\n\n    int i;\n\n    struct utsname uuts;\n\n    ......\n\n    ...设置和初始化各种资源，这里就省略了，有兴趣的自己看看\n    \n    ......\n\n    //最主要的是这行\n    uwsgi_start((void *) uwsgi.argv);\n}\n\nint uwsgi_start(void *v_argv) {\n\n    ......\n\n    简化摘要一些主要的代码\n\n    ......\n\n    ... 题外话，这里是创建一个多线程的共享内存空间，后面uwsgi_setup_workers的时候会用到。\n        因为uwsgi有一个master进程，可以监测各个子进程的状态，所以需要一块匿名共享内存\n    // initialize sharedareas\n    uwsgi_sharedareas_init();\n\n    // setup queue\n    if (uwsgi.queue_size > 0) {\n        uwsgi_init_queue();\n    }\n\n    ... 这里很重要，uwsgi.p是一个接口，uwsgi中部署的app在这里初始化（在uwsgi中，部署的APP需要所对应语言的插件，如python就用python插件）\n        后面也会看到，实际上uwsgi所执行的python代码，其所有模块的import都在这里执行\n    // initialize request plugin only if workers or master are available\n    if (uwsgi.sockets || uwsgi.master_process || uwsgi.no_server || uwsgi.command_mode || uwsgi.loop) {\n        for (i = 0; i < 256; i++) {\n            if (uwsgi.p[i]->init) {\n                uwsgi.p[i]->init();\n            }\n        }\n    }\n\n    // again check for workers/sockets...\n    if (uwsgi.sockets || uwsgi.master_process || uwsgi.no_server || uwsgi.command_mode || uwsgi.loop) {\n        for (i = 0; i < 256; i++) {\n            if (uwsgi.p[i]->post_init) {\n                uwsgi.p[i]->post_init();\n            }\n        }\n    }\n\n    。。。这里主要是设置各个worker的共享内存空间\n    // initialize workers/master shared memory segments\n    uwsgi_setup_workers();\n\n    // here we spawn the workers...\n    if (!uwsgi.status.is_cheap) {\n        if (uwsgi.cheaper && uwsgi.cheaper_count) {\n            int nproc = uwsgi.cheaper_initial;\n            if (!nproc)\n                nproc = uwsgi.cheaper_count;\n            for (i = 1; i <= uwsgi.numproc; i++) {\n                if (i <= nproc) {\n                    if (uwsgi_respawn_worker(i))\n                        break;\n                    uwsgi.respawn_delta = uwsgi_now();\n                }\n                else {\n                    uwsgi.workers[i].cheaped = 1;\n                }\n            }\n        }\n        else {\n            for (i = 2 - uwsgi.master_process; i < uwsgi.numproc + 1; i++) {\n                。。。这里就是根据我们设置的进程数，去fork子进程\n                if (uwsgi_respawn_worker(i))\n                    break;\n                uwsgi.respawn_delta = uwsgi_now();\n            }\n        }\n    }\n\n\n    // END OF INITIALIZATION\n    return 0;\n\n}\n\nint uwsgi_respawn_worker(int wid) {\n\n    。。。主要是这行代码，fork子进程，里面就不跟了\n    pid_t pid = uwsgi_fork(uwsgi.workers[wid].name);\n\n    if (pid == 0) {\n        signal(SIGWINCH, worker_wakeup);\n        signal(SIGTSTP, worker_wakeup);\n        uwsgi.mywid = wid;\n        uwsgi.mypid = getpid();\n        // pid is updated by the master\n        //uwsgi.workers[uwsgi.mywid].pid = uwsgi.mypid;\n        // OVERENGINEERING (just to be safe)\n        uwsgi.workers[uwsgi.mywid].id = uwsgi.mywid;\n        /*\n           uwsgi.workers[uwsgi.mywid].harakiri = 0;\n           uwsgi.workers[uwsgi.mywid].user_harakiri = 0;\n           uwsgi.workers[uwsgi.mywid].rss_size = 0;\n           uwsgi.workers[uwsgi.mywid].vsz_size = 0;\n         */\n        // do not reset worker counters on reload !!!\n        //uwsgi.workers[uwsgi.mywid].requests = 0;\n        // ...but maintain a delta counter (yes this is racy in multithread)\n        //uwsgi.workers[uwsgi.mywid].delta_requests = 0;\n        //uwsgi.workers[uwsgi.mywid].failed_requests = 0;\n        //uwsgi.workers[uwsgi.mywid].respawn_count++;\n        //uwsgi.workers[uwsgi.mywid].last_spawn = uwsgi.current_time;\n\n    }\n    else if (pid < 1) {\n        uwsgi_error(\"fork()\");\n    }\n    else {\n        // the pid is set only in the master, as the worker should never use it\n        uwsgi.workers[wid].pid = pid;\n\n        if (respawns > 0) {\n            uwsgi_log(\"Respawned uWSGI worker %d (new pid: %d)\\n\", wid, (int) pid);\n        }\n        else {\n            uwsgi_log(\"spawned uWSGI worker %d (pid: %d, cores: %d)\\n\", wid, pid, uwsgi.cores);\n        }\n    }\n\n    return 0;\n}\n\nint uwsgi_run() {\n\n    。。。也是捡重要的摘抄一些\n        如果pid是master，就执行master_loop\n        如果pid是worker，就执行uwsgi_worker_run\n\n    // !!! from now on, we could be in the master or in a worker !!!\n    if (getpid() == masterpid && uwsgi.master_process == 1) {\n        (void) master_loop(uwsgi.argv, uwsgi.environ);\n    }\n\n    //from now on the process is a real worker\n    uwsgi_worker_run();\n    // never here\n    _exit(0);\n\n}\n\nvoid uwsgi_worker_run() {\n\n    int i;\n\n    if (uwsgi.lazy || uwsgi.lazy_apps) {\n        uwsgi_init_all_apps();\n    }\n\n    uwsgi_ignition();\n\n    // never here\n    exit(0);\n\n}\n\nvoid uwsgi_ignition() {\n\n    if (uwsgi.loop) {\n        void (*u_loop) (void) = uwsgi_get_loop(uwsgi.loop);\n        if (!u_loop) {\n            uwsgi_log(\"unavailable loop engine !!!\\n\");\n            exit(1);\n        }\n        if (uwsgi.mywid == 1) {\n            uwsgi_log(\"*** running %s loop engine [addr:%p] ***\\n\", uwsgi.loop, u_loop);\n        }\n        u_loop();\n        uwsgi_log(\"your loop engine died. R.I.P.\\n\");\n    }\n    else {\n        。。。子进程的循环体，一般是用simple_loop\n        if (uwsgi.async < 1) {\n            simple_loop();\n        }\n        else {\n            async_loop();\n        }\n    }\n\n    // end of the process...\n    end_me(0);\n}\n\n\n。。。一直到这里，在子进程的loop里面才开始创建接收处理request请求的线程\n    线程的执行函数simple_loop_run也是一个循环，基本上都是常规步奏，accept，receive, response...，后面就不继续追下去了\n    在reciev接到请求的数据后，会通过python_call的方法调用python脚本的wsgi函数，处理这个请求\nvoid simple_loop() {\n    uwsgi_loop_cores_run(simple_loop_run);\n}\n\nvoid uwsgi_loop_cores_run(void *(*func) (void *)) {\n    int i;\n    for (i = 1; i < uwsgi.threads; i++) {\n        long j = i;\n        pthread_create(&uwsgi.workers[uwsgi.mywid].cores[i].thread_id, &uwsgi.threads_attr, func, (void *) j);\n    }\n    long y = 0;\n    func((void *) y);\n}\n```\n　　简单来说，就是uwsgi中执行python脚本和直接运行python脚本是不同的。uwsgi执行python脚本是通过调用python c api的方法，首先通过调用api载入python脚本中的module，这时候，像最开始的实例代码一样module import中的相关代码会被执行，所有的全局变量在进程中被创建和初始化。然后uwsgi创建线程，开始处理请求调用python api（python_call），执行python脚本中处理请求的函数（wsgi接口），因为module import在线程创建之前已经执行了，所以之前在进程中的共享数据在线程中是可以访问的。这里就是需要我们着重注意的，在访问这些线程间共享数据的时候需要加锁，或者在编写python脚本的时候尽量少用全局变量而多用单例模式，避免不必要的采坑。\n　　其实上面所述只是对我遇到问题的一个简化，为了帮助大家弄明白uwsgi多线程执行python wsgi接口的相关问题。我所遇到的问题是在处理请求的函数中，调用了一个在全局中创建的gearman client，这个client库不是线程安全的，使用中也没有加锁。当请求的并发比较大的时候，gearman client这个库就会报出一些连接的异常。\n　　由于GIL的存在，Python的多线程并不能充分的利用多核的优势。在实际项目中，我们常常使用多进程来取代多线程的方法，来实现一些需要并发的业务。然而，进程的开销毕竟比较大，并且设计进程间的数据同步，进程间通信等操作相对线程来说十分的复杂，也是开发中的一个痛点，我们经常为了性能而放弃使用python转而使用c多线程的方案，但是确实降低了代码的可维护性，增加了代码的成本。\n　　在了解了uwsgi的多线程结构之后，其实我们也可以学习其通过多线程调用python c api的方法，使用c的线程调用python的业务代码，将需要共享的数据放在c线程创建之前进行module import。将c多线程的部分提取出来成为一个框架，工程师只需要书写python的业务代码并在注意在使用共享数据的时候加锁。框架部分交由专业的有经验的c/python工程师进行维护，这样在不牺牲代码生产效率的前提下，提升了程序的性能。\n　　后记：其实这个问题并不是十分的复杂，暴露的问题是对于uwsgi的代码结构，和python c api以及c调用python的方法和相关概念等不是非常的熟练，暴露了自己知识体系中的短板。由于那几天同时在开发几个需求，没有对问题进行详细的测试，没有仔细的分析和查找Trackback中的错误，反而是一直在怀疑被调用方的接口性能问题。其实这个团队在交流上确实也存在一些问题，争论基本上靠喊，靠抢话，不是就是论事而是经常人身攻击。每当有工程师的方案确实在理，确实证明是可用的时候，反对的人也宁死不妥协。。。这大概就是像新浪这样臃肿老旧缺少活力的大公司的通病吧（一点吐槽，熟人请无视）。\n","slug":"多线程C调用python-api的陷阱","published":1,"updated":"2016-01-20T04:26:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfeu000i0qi56iki5lni","sticky":0},{"title":"memcached几个容易被忽略但非常有用的命令","date":"2014-07-14T03:25:29.000Z","_content":"# 一、CAS和GETS\n　　Memcached从1.2.4版本新增CAS(Check and Set)协议，用于处理同一个ITEM（key-value）被多个session更新修改时的数据一致性问题。\n　　假设有两个session（A、B），要同时修改某个key的值x，并且修改的数据是基于原来数据的一个计算的结果。session A和B同时得到了key的值x，session A经过计算后应该更新为y，session B经过计算后也更新为y，但是session B其实期望的是拿到y值，并将其计算为Z后更新。造成这个问题的原因就是缺少一个类似于MySQL的事务，用于数据并发修改的一致性问题。\n<!--more-->\n　　CAS命令着眼于解决一定的并发修改问题，引入了乐观锁的概念。在试图修改某个KEY的值之前，先由GETS命令得到某个KEY的值及其版本号，完成数据操作更新数据时，使用CAS谨慎更新，比较版本号是否与本地的版本号一致，否则放弃此次的修改。\n　　Memcached在默认开启CAS协议后，每个key关联有一个64-bit长度的long型惟一数值，表示该key对应value的版本号。这个数值由Memcached server产生，从1开始，且同一Memcached server不会重复。在两种情况下这个版本数值会加1：\n1. 新增一个key-value对。\n2. 对某已有的key对应的value值更新成功。删除item版本值不会减小。\n\n　　首先为了获得KEY值的版本号，引入了GETS命令，可以发现GETS命令比GET命令多返回了一个数字，这个数字就是上面我们提到的KEY值的版本号。        然后是CAS命令，与SET命令类似，只是在最后面多了一个参数，也就是key值得版本号，只有版本号与存储的数据版本号一致时，更新操作才会生效。\n```bash\nset a 0 0 1\nx\nSTORED\n\ngets a\nVALUE a 0 1 1  //最后一位就是a的版本号\nx\nEND\n\nset a 0 0 1\ny\nSTORED\n\ngets a\nVALUE a 0 1 2    //新增或修改之后，版本号都会增加\ny\n\ncas a 0 0 1 1\n//cas更新的时候，不同于set操作，最后一位要指定版本号，当本地版本号和服务器版本号相同的时候，更新才会有效\nx\nEXISTS\n\ncas a 0 0 1 2\ny\nSTORED\n```\n# 二、stats items和stats cachedump\n　　你曾经是否也有想知道memcached里面都存了哪些数据的需求，你是否也曾经在寻找一个方法能像redis一样可以遍历memcached所有的key\n　　其实就是应用我们平时经常用到的stats方法。stats方法不仅能获得memcached的一个概况信息，如果加上子命令还可以获得更多的更加详细的信息。如slabs，items等。\n　　stats items命令，可以获得memcached内item组的相关信息，如分组内item的数量，踢掉次数等。后面运行cachedump命令的时候会用到这个命令的返回信息（item组序号）。\n　　stats cachedump命令，可以将某个slab中的items全部dump出来，第一个参数就是上面stats items返回的items组号，也就是slab的编号，第二个参数为一次显示多少个item信息，如果为0就显示这个item组的全部items，第二列就是key。\n```Bash\nstats items\nSTAT items:1:number 3\nSTAT items:1:age 943\nSTAT items:1:evicted 0\nSTAT items:1:evicted_nonzero 0\nSTAT items:1:evicted_time 0\nSTAT items:1:outofmemory 0\nSTAT items:1:tailrepairs 0\nSTAT items:1:reclaimed 0\nSTAT items:1:expired_unfetched 0\nSTAT items:1:evicted_unfetched 0\nEND\n\nstats cachedump 1 0\nITEM c [5 b; 1405246917 s]\nITEM b [1 b; 1405246917 s]\nITEM a [1 b; 1405246917 s]\nEND\n```\n　　虽然应用这两个命令并不能一次显示全部的key，但是如果我们自己根据stats items的返回值自己做一次迭代，或者仅仅是为了手动做几个item的抽样，那么就能很好的帮助我们了解memcached中数据的情况。\n","source":"_posts/memcached几个容易被忽略但非常有用的命令.md","raw":"title: memcached几个容易被忽略但非常有用的命令\ndate: 2014-07-14 11:25:29\ntags: memcached\n---\n# 一、CAS和GETS\n　　Memcached从1.2.4版本新增CAS(Check and Set)协议，用于处理同一个ITEM（key-value）被多个session更新修改时的数据一致性问题。\n　　假设有两个session（A、B），要同时修改某个key的值x，并且修改的数据是基于原来数据的一个计算的结果。session A和B同时得到了key的值x，session A经过计算后应该更新为y，session B经过计算后也更新为y，但是session B其实期望的是拿到y值，并将其计算为Z后更新。造成这个问题的原因就是缺少一个类似于MySQL的事务，用于数据并发修改的一致性问题。\n<!--more-->\n　　CAS命令着眼于解决一定的并发修改问题，引入了乐观锁的概念。在试图修改某个KEY的值之前，先由GETS命令得到某个KEY的值及其版本号，完成数据操作更新数据时，使用CAS谨慎更新，比较版本号是否与本地的版本号一致，否则放弃此次的修改。\n　　Memcached在默认开启CAS协议后，每个key关联有一个64-bit长度的long型惟一数值，表示该key对应value的版本号。这个数值由Memcached server产生，从1开始，且同一Memcached server不会重复。在两种情况下这个版本数值会加1：\n1. 新增一个key-value对。\n2. 对某已有的key对应的value值更新成功。删除item版本值不会减小。\n\n　　首先为了获得KEY值的版本号，引入了GETS命令，可以发现GETS命令比GET命令多返回了一个数字，这个数字就是上面我们提到的KEY值的版本号。        然后是CAS命令，与SET命令类似，只是在最后面多了一个参数，也就是key值得版本号，只有版本号与存储的数据版本号一致时，更新操作才会生效。\n```bash\nset a 0 0 1\nx\nSTORED\n\ngets a\nVALUE a 0 1 1  //最后一位就是a的版本号\nx\nEND\n\nset a 0 0 1\ny\nSTORED\n\ngets a\nVALUE a 0 1 2    //新增或修改之后，版本号都会增加\ny\n\ncas a 0 0 1 1\n//cas更新的时候，不同于set操作，最后一位要指定版本号，当本地版本号和服务器版本号相同的时候，更新才会有效\nx\nEXISTS\n\ncas a 0 0 1 2\ny\nSTORED\n```\n# 二、stats items和stats cachedump\n　　你曾经是否也有想知道memcached里面都存了哪些数据的需求，你是否也曾经在寻找一个方法能像redis一样可以遍历memcached所有的key\n　　其实就是应用我们平时经常用到的stats方法。stats方法不仅能获得memcached的一个概况信息，如果加上子命令还可以获得更多的更加详细的信息。如slabs，items等。\n　　stats items命令，可以获得memcached内item组的相关信息，如分组内item的数量，踢掉次数等。后面运行cachedump命令的时候会用到这个命令的返回信息（item组序号）。\n　　stats cachedump命令，可以将某个slab中的items全部dump出来，第一个参数就是上面stats items返回的items组号，也就是slab的编号，第二个参数为一次显示多少个item信息，如果为0就显示这个item组的全部items，第二列就是key。\n```Bash\nstats items\nSTAT items:1:number 3\nSTAT items:1:age 943\nSTAT items:1:evicted 0\nSTAT items:1:evicted_nonzero 0\nSTAT items:1:evicted_time 0\nSTAT items:1:outofmemory 0\nSTAT items:1:tailrepairs 0\nSTAT items:1:reclaimed 0\nSTAT items:1:expired_unfetched 0\nSTAT items:1:evicted_unfetched 0\nEND\n\nstats cachedump 1 0\nITEM c [5 b; 1405246917 s]\nITEM b [1 b; 1405246917 s]\nITEM a [1 b; 1405246917 s]\nEND\n```\n　　虽然应用这两个命令并不能一次显示全部的key，但是如果我们自己根据stats items的返回值自己做一次迭代，或者仅仅是为了手动做几个item的抽样，那么就能很好的帮助我们了解memcached中数据的情况。\n","slug":"memcached几个容易被忽略但非常有用的命令","published":1,"updated":"2016-01-20T04:27:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfez000r0qi5dt4633rq","sticky":0},{"title":"Tornado生产骨架——mownfish介绍","date":"2013-12-03T07:39:03.000Z","_content":">曾经给大家介绍了许多优秀的开源项目，今天为大家介绍我的在githup上开源的一个tornado生产骨架——[mownfish](https://github.com/Ethan-Zhang/mownfish)，欢迎大家拍砖~\n\n　　Tornado是用python写的一个基于linux epoll的异步非阻塞IO实时框架，最早产生于FriendFeed，09年被Facebook收购并开源。这个框架被广泛的应用于互联网实时信息处理领域，如long polling、websocket等。将晦涩难以理解的linux epoll的相关操作封装在了IOLoop，IOStream等模块中，方便开发者更快捷的使用linux epoll的异步非阻塞IO。其代码结构和运行效率都像她的名字一样，tornado——龙卷风，轻量、迅捷、快速。然而如此强大的框架也有许多不足之处，因为其依赖异步非阻塞的IO工作方式，如果代码内有IO操作阻塞了进程，将会使整个服务不能响应。所以就需要我们使用的相关涉及网络IO的客户端如MySQL-client等也是支持异步的，这时非常复杂的，因为大部分主流的客户端库都是同步的IO方式。第二，其代码和文档符合Facebook开源项目的一贯风格，基本无文档，注释也很少，需要开发者查看具体的框架代码以理解其实现，不然会有很多的谬用。第三，tornado是以python模块的形式发布了代码，并非像姜哥或者其他的php、rails风格的框架等，自己的应用代码就是直接写在框架内部，也就是说框架已经规范了应用的代码结构。tornado需要自己来实现应用的代码结构，不管是tornado的新手还是老手，在新建一个项目的时候都要或多或少的重复写一些项目的初始化代码，完成代码的骨架。\n　　mownfish的产生就是为了解决代码骨架的问题。mownfish，其名字来源于我工作过的一家公司的logo，一个脸长得非常怪的鱼，我称之为怪脸鱼。mownfish是一个基于tornado的生产骨架，目的是帮助开发者快速、高效、规范的生成一个应用的代码骨架，并增加少量的如log，脚本等功能。\n<!--more-->\n\n　　mownfish有以下几个特点：\n1. 生成代码骨架\n　　    mownfish规范了应用的代码结构。如下图所示，cmd中存放的是应用的启动入口，可以以consol_script的形式在setup打包中创建模块的entry_point。wsgi.py是tornado非阻塞server的基础，创建了http_server以及Application的实例。error.py自定义了用户级别的异常，如参数异常，DB异常等。与周期性定时器相关的代码全部放到timer_task.py中。domain模块中存放和handler或与handler相关的类，domain.__init__中定义了应用的路由信息，以应用名为key组织了字典，在wsgi中进行动态的加载。base_handler.py为自定义的handler的基类，实现了几个参数过滤的方法。util模块中存放log、config以及其他通用的方法，db抽象db相关操作。\n![tree](http://7xpwqp.com1.z0.glb.clouddn.com/2013-12-03-01.png) \n2. 初始化脚本fishing\n　　通过fishing脚本，可以一键由mownfish部署一个以自己项目名命名的python工程目录，包括日志名，应用路由名等均在脚本中自动修改，并可以自动添加项目权限头。\n```Bash\nmownfish/script/fishing $dst_path -n $project_name -l $lisense_file\n```\n3. 日志管理\n　　基于后端服务的响应时间、吞吐量等性能的考量，mownfish选择基于tornado2.4版本进行开发，并没有使用最新的3.1版本。在tornado3.x版本之前还没有默认的log模块，所以mownfish自己实现了一个log模块，提供了一个全局logger，方便对access日志和错误日志等进行记录。\n\n　　目前这个生产框架已经在实际在几个项目中应用了，应对敏捷开发上还是很明显的。希望能给应用tornado框架开发的人带来便利，欢迎各种在github上提出issue或直接pull request。如果觉得对你有帮助还请在github上留个星。\n","source":"_posts/Tornado生产骨架——mownfish介绍.md","raw":"title: Tornado生产骨架——mownfish介绍\ndate: 2013-12-03 15:39:03\ntags: [Tornado, 异步, 开源]\n---\n>曾经给大家介绍了许多优秀的开源项目，今天为大家介绍我的在githup上开源的一个tornado生产骨架——[mownfish](https://github.com/Ethan-Zhang/mownfish)，欢迎大家拍砖~\n\n　　Tornado是用python写的一个基于linux epoll的异步非阻塞IO实时框架，最早产生于FriendFeed，09年被Facebook收购并开源。这个框架被广泛的应用于互联网实时信息处理领域，如long polling、websocket等。将晦涩难以理解的linux epoll的相关操作封装在了IOLoop，IOStream等模块中，方便开发者更快捷的使用linux epoll的异步非阻塞IO。其代码结构和运行效率都像她的名字一样，tornado——龙卷风，轻量、迅捷、快速。然而如此强大的框架也有许多不足之处，因为其依赖异步非阻塞的IO工作方式，如果代码内有IO操作阻塞了进程，将会使整个服务不能响应。所以就需要我们使用的相关涉及网络IO的客户端如MySQL-client等也是支持异步的，这时非常复杂的，因为大部分主流的客户端库都是同步的IO方式。第二，其代码和文档符合Facebook开源项目的一贯风格，基本无文档，注释也很少，需要开发者查看具体的框架代码以理解其实现，不然会有很多的谬用。第三，tornado是以python模块的形式发布了代码，并非像姜哥或者其他的php、rails风格的框架等，自己的应用代码就是直接写在框架内部，也就是说框架已经规范了应用的代码结构。tornado需要自己来实现应用的代码结构，不管是tornado的新手还是老手，在新建一个项目的时候都要或多或少的重复写一些项目的初始化代码，完成代码的骨架。\n　　mownfish的产生就是为了解决代码骨架的问题。mownfish，其名字来源于我工作过的一家公司的logo，一个脸长得非常怪的鱼，我称之为怪脸鱼。mownfish是一个基于tornado的生产骨架，目的是帮助开发者快速、高效、规范的生成一个应用的代码骨架，并增加少量的如log，脚本等功能。\n<!--more-->\n\n　　mownfish有以下几个特点：\n1. 生成代码骨架\n　　    mownfish规范了应用的代码结构。如下图所示，cmd中存放的是应用的启动入口，可以以consol_script的形式在setup打包中创建模块的entry_point。wsgi.py是tornado非阻塞server的基础，创建了http_server以及Application的实例。error.py自定义了用户级别的异常，如参数异常，DB异常等。与周期性定时器相关的代码全部放到timer_task.py中。domain模块中存放和handler或与handler相关的类，domain.__init__中定义了应用的路由信息，以应用名为key组织了字典，在wsgi中进行动态的加载。base_handler.py为自定义的handler的基类，实现了几个参数过滤的方法。util模块中存放log、config以及其他通用的方法，db抽象db相关操作。\n![tree](http://7xpwqp.com1.z0.glb.clouddn.com/2013-12-03-01.png) \n2. 初始化脚本fishing\n　　通过fishing脚本，可以一键由mownfish部署一个以自己项目名命名的python工程目录，包括日志名，应用路由名等均在脚本中自动修改，并可以自动添加项目权限头。\n```Bash\nmownfish/script/fishing $dst_path -n $project_name -l $lisense_file\n```\n3. 日志管理\n　　基于后端服务的响应时间、吞吐量等性能的考量，mownfish选择基于tornado2.4版本进行开发，并没有使用最新的3.1版本。在tornado3.x版本之前还没有默认的log模块，所以mownfish自己实现了一个log模块，提供了一个全局logger，方便对access日志和错误日志等进行记录。\n\n　　目前这个生产框架已经在实际在几个项目中应用了，应对敏捷开发上还是很明显的。希望能给应用tornado框架开发的人带来便利，欢迎各种在github上提出issue或直接pull request。如果觉得对你有帮助还请在github上留个星。\n","slug":"Tornado生产骨架——mownfish介绍","published":1,"updated":"2016-01-25T10:45:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxff3000u0qi51e77iasr","sticky":0},{"title":"Python多进程log日志切分错误的解决方案","date":"2013-11-18T08:34:42.000Z","_content":"　　在生产环境中，log一般按照时间进行切分，如在23:59:59切分一天的日志，以便进行分析。在python中常用内建的logging模块实现。\n```Python\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)   \nlog_file = 'tornadolog.log'\ntimelog = timelog = logging.handlers.TimedRotatingFileHandler(log_file,\n                                                            'midnight',\n                                                            1, 0)\nlogger.addHandler(timelog)\n\nlogger.info('Hello log')\n```\n　　但是，像tornado这种推荐进行多进程部署的框架，在类似的日志切分上会发生错误，原因是单个的日志文件作为进程间的共享资源，当其中一个进程进行日志切分的时候，实际上是将原来的日志文件改名，然后新建一个日志文件，文件操作描述符fd发生了改变，其它的进程不知道这个操作，再次写入日志的时候因为找不到新的文件描述符发生异常。\n解决方法也很简单，我们可以是每个tornado进程都有一个自己的日志文件，通过进程的task_id进行区分，避免进程间共享资源的操作。\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Copyright 2012 Ethan Zhang<http://github.com/Ethan-Zhang>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the                                                    \n# License for the specific language governing permissions and limitations\n# under the License.\n\n\nimport signal                                                                                                                 \nimport os                                                                                                                     \nimport logging                                                                                                                \nimport logging.handlers                                                                                                       \n\nimport tornado\nimport tornado.netutil                                                                                                        \nimport tornado.process                                                                                                        \nfrom tornado.ioloop import IOLoop                                                                                             \nfrom tornado.httpserver import HTTPServer                                                                                     \n\ndef handle_request(request):\n    message = \"You requested %s\\n\" % request.uri                                                                              \n    request.write(\"HTTP/1.1 200 OK\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (                                                       \n                               len(message), message))\n    request.finish()\n\ndef kill_server(sig, frame):\n\n    IOLoop.instance().stop()\n\n\ndef main():\n\n    signal.signal(signal.SIGPIPE, signal.SIG_IGN);\n    signal.signal(signal.SIGINT, kill_server)\n    signal.signal(signal.SIGQUIT, kill_server)\n    signal.signal(signal.SIGTERM, kill_server)\n    signal.signal(signal.SIGHUP, kill_server)\n\n    sockets = tornado.netutil.bind_sockets(9204)\n    task_id = tornado.process.fork_processes(2)\n    #task_id为fork_processes返回的子进程编号\n\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    log_file = 'tornadolog.log.%d' % (task_id)\n    #以子进程编号命名自己的log文件名\n    timelog = timelog = logging.handlers.TimedRotatingFileHandler(log_file,\n                                                                'midnight',\n                                                                1, 0)\n    logger.addHandler(timelog)\n\n    server = HTTPServer(handle_request)\n    server.add_sockets(sockets)\n\n    logger.info('Server Starting...')\n\n    IOLoop.instance().start()\n    server.stop()\n    IOLoop.instance().stop()\n\nif __name__ == '__main__':\n    main()\n```\n***\n__2013-11-25新增__\n***\n　　其实我们分析Python的内建库logging的源码就能发现问题\n<!--more-->\n```Python\ndef doRollover(self):\n    \"\"\"\n    do a rollover; in this case, a date/time stamp is appended to the filename\n    when the rollover happens.  However, you want the file to be named for the\n    start of the interval, not the current time.  If there is a backup count,\n    then we have to get a list of matching filenames, sort them and remove\n    the one with the oldest suffix.\n    \"\"\"\n    if self.stream:\n        self.stream.close()\n    # get the time that this sequence started at and make it a TimeTuple\n    t = self.rolloverAt - self.interval\n    if self.utc:\n        timeTuple = time.gmtime(t)\n    else:\n        timeTuple = time.localtime(t)\n    dfn = self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)\n    if os.path.exists(dfn):\n        os.remove(dfn)\n    os.rename(self.baseFilename, dfn)\n    if self.backupCount > 0:\n        # find the oldest log file and delete it\n        #s = glob.glob(self.baseFilename + \".20*\")\n        #if len(s) > self.backupCount:\n        #    s.sort()\n        #    os.remove(s[0])\n        for s in self.getFilesToDelete():\n            os.remove(s)\n    #print \"%s -> %s\" % (self.baseFilename, dfn)\n    self.mode = 'a'\n    self.stream = self._open()\n    currentTime = int(time.time())\n    newRolloverAt = self.computeRollover(currentTime)\n    while newRolloverAt <= currentTime:\n        newRolloverAt = newRolloverAt + self.interval\n    #If DST changes and midnight or weekly rollover, adjust for this.\n    if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n        dstNow = time.localtime(currentTime)[-1]\n        dstAtRollover = time.localtime(newRolloverAt)[-1]\n        if dstNow != dstAtRollover:\n            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                newRolloverAt = newRolloverAt - 3600\n            else:           # DST bows out before next rollover, so we need to add an hour\n                newRolloverAt = newRolloverAt + 3600\n    self.rolloverAt = newRolloverAt\n```\n　　第18-31行，每次TimedRotatingHandler做切分操作时，所做的步骤如下：\n1. 如现在的文件为mownfish.log, 切分后的文件名为mownfish.log.2013-11-24\n2. 判断切分后重命名的文件mownfish.log.2013-11-24是否存在，如果存在就删除\n3. 将目前的日志文件mownfish.log重命名为mownfish.log.2013-11-24\n4. 以“w”模式打开一个新文件mownfish.log。\n\n　　如果是多进程的应用程序，如tornado，将会出现异常。比如某个进程刚刚完成了第二步，将mownfish.log重命名为mownfish.log.2013-11-24。另外一个进程刚刚开始执行第二步，此时进程1还没有进行到第3步，即创建一个新的mownfish.log，所以进程2找不到mownfish.log，程序抛出异常。另外每次以W模式打开，也会使新生成的mownfish.log文件内容被重复的清除多次。\n　　解决方案为创建类，继承自TimedRotatingHandler，重写其切分方法doRollover()方法。流程修改为：\n1. 判断切分后重命名的文件mownfish.log.2013-11-24是否存在，如不存在将日志文件mownfish.log重命名为mownfish.log.2013-11-24\n2. 以’a‘模式打开文件mownfish.log\n\n　　这样当进程1重命名之后，进程2就不会重复执行重命名的动作了。\n```Python\ndef doRollover(self):\n    \"\"\"\n    do a rollover; in this case, a date/time stamp is appended to the filename\n    when the rollover happens.  However, you want the file to be named for the\n    start of the interval, not the current time.  If there is a backup count,\n    then we have to get a list of matching filenames, sort them and remove\n    the one with the oldest suffix.\n    \"\"\"\n    if self.stream:\n        self.stream.close()\n    # get the time that this sequence started at and make it a TimeTuple\n    t = self.rolloverAt - self.interval\n    if self.utc:\n        timeTuple = time.gmtime(t)\n    else:\n        timeTuple = time.localtime(t)\n    dfn = self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)\n    #if os.path.exists(dfn):\n    #    os.remove(dfn)\n    if not os.path.exists(dfn):\n        os.rename(self.baseFilename, dfn)\n    if self.backupCount > 0:\n        # find the oldest log file and delete it\n        #s = glob.glob(self.baseFilename + \".20*\")\n        #if len(s) > self.backupCount:\n        #    s.sort()\n        #    os.remove(s[0])\n        for s in self.getFilesToDelete():\n            os.remove(s)\n    #print \"%s -> %s\" % (self.baseFilename, dfn)\n    self.mode = 'a'\n    self.stream = self._open()\n    currentTime = int(time.time())\n    newRolloverAt = self.computeRollover(currentTime)\n    while newRolloverAt <= currentTime:\n        newRolloverAt = newRolloverAt + self.interval\n    #If DST changes and midnight or weekly rollover, adjust for this.\n    if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n        dstNow = time.localtime(currentTime)[-1]\n        dstAtRollover = time.localtime(newRolloverAt)[-1]\n        if dstNow != dstAtRollover:\n            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                newRolloverAt = newRolloverAt - 3600\n            else:           # DST bows out before next rollover, so we need to add an hour\n                newRolloverAt = newRolloverAt + 3600\n    self.rolloverAt = newRolloverAt\n```\n","source":"_posts/Python多进程log日志切分错误的解决方案.md","raw":"title: Python多进程log日志切分错误的解决方案\ndate: 2013-11-18 16:34:42\ntags: [Python, Tornado, 日志切分]\n---\n　　在生产环境中，log一般按照时间进行切分，如在23:59:59切分一天的日志，以便进行分析。在python中常用内建的logging模块实现。\n```Python\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)   \nlog_file = 'tornadolog.log'\ntimelog = timelog = logging.handlers.TimedRotatingFileHandler(log_file,\n                                                            'midnight',\n                                                            1, 0)\nlogger.addHandler(timelog)\n\nlogger.info('Hello log')\n```\n　　但是，像tornado这种推荐进行多进程部署的框架，在类似的日志切分上会发生错误，原因是单个的日志文件作为进程间的共享资源，当其中一个进程进行日志切分的时候，实际上是将原来的日志文件改名，然后新建一个日志文件，文件操作描述符fd发生了改变，其它的进程不知道这个操作，再次写入日志的时候因为找不到新的文件描述符发生异常。\n解决方法也很简单，我们可以是每个tornado进程都有一个自己的日志文件，通过进程的task_id进行区分，避免进程间共享资源的操作。\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Copyright 2012 Ethan Zhang<http://github.com/Ethan-Zhang>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the                                                    \n# License for the specific language governing permissions and limitations\n# under the License.\n\n\nimport signal                                                                                                                 \nimport os                                                                                                                     \nimport logging                                                                                                                \nimport logging.handlers                                                                                                       \n\nimport tornado\nimport tornado.netutil                                                                                                        \nimport tornado.process                                                                                                        \nfrom tornado.ioloop import IOLoop                                                                                             \nfrom tornado.httpserver import HTTPServer                                                                                     \n\ndef handle_request(request):\n    message = \"You requested %s\\n\" % request.uri                                                                              \n    request.write(\"HTTP/1.1 200 OK\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (                                                       \n                               len(message), message))\n    request.finish()\n\ndef kill_server(sig, frame):\n\n    IOLoop.instance().stop()\n\n\ndef main():\n\n    signal.signal(signal.SIGPIPE, signal.SIG_IGN);\n    signal.signal(signal.SIGINT, kill_server)\n    signal.signal(signal.SIGQUIT, kill_server)\n    signal.signal(signal.SIGTERM, kill_server)\n    signal.signal(signal.SIGHUP, kill_server)\n\n    sockets = tornado.netutil.bind_sockets(9204)\n    task_id = tornado.process.fork_processes(2)\n    #task_id为fork_processes返回的子进程编号\n\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    log_file = 'tornadolog.log.%d' % (task_id)\n    #以子进程编号命名自己的log文件名\n    timelog = timelog = logging.handlers.TimedRotatingFileHandler(log_file,\n                                                                'midnight',\n                                                                1, 0)\n    logger.addHandler(timelog)\n\n    server = HTTPServer(handle_request)\n    server.add_sockets(sockets)\n\n    logger.info('Server Starting...')\n\n    IOLoop.instance().start()\n    server.stop()\n    IOLoop.instance().stop()\n\nif __name__ == '__main__':\n    main()\n```\n***\n__2013-11-25新增__\n***\n　　其实我们分析Python的内建库logging的源码就能发现问题\n<!--more-->\n```Python\ndef doRollover(self):\n    \"\"\"\n    do a rollover; in this case, a date/time stamp is appended to the filename\n    when the rollover happens.  However, you want the file to be named for the\n    start of the interval, not the current time.  If there is a backup count,\n    then we have to get a list of matching filenames, sort them and remove\n    the one with the oldest suffix.\n    \"\"\"\n    if self.stream:\n        self.stream.close()\n    # get the time that this sequence started at and make it a TimeTuple\n    t = self.rolloverAt - self.interval\n    if self.utc:\n        timeTuple = time.gmtime(t)\n    else:\n        timeTuple = time.localtime(t)\n    dfn = self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)\n    if os.path.exists(dfn):\n        os.remove(dfn)\n    os.rename(self.baseFilename, dfn)\n    if self.backupCount > 0:\n        # find the oldest log file and delete it\n        #s = glob.glob(self.baseFilename + \".20*\")\n        #if len(s) > self.backupCount:\n        #    s.sort()\n        #    os.remove(s[0])\n        for s in self.getFilesToDelete():\n            os.remove(s)\n    #print \"%s -> %s\" % (self.baseFilename, dfn)\n    self.mode = 'a'\n    self.stream = self._open()\n    currentTime = int(time.time())\n    newRolloverAt = self.computeRollover(currentTime)\n    while newRolloverAt <= currentTime:\n        newRolloverAt = newRolloverAt + self.interval\n    #If DST changes and midnight or weekly rollover, adjust for this.\n    if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n        dstNow = time.localtime(currentTime)[-1]\n        dstAtRollover = time.localtime(newRolloverAt)[-1]\n        if dstNow != dstAtRollover:\n            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                newRolloverAt = newRolloverAt - 3600\n            else:           # DST bows out before next rollover, so we need to add an hour\n                newRolloverAt = newRolloverAt + 3600\n    self.rolloverAt = newRolloverAt\n```\n　　第18-31行，每次TimedRotatingHandler做切分操作时，所做的步骤如下：\n1. 如现在的文件为mownfish.log, 切分后的文件名为mownfish.log.2013-11-24\n2. 判断切分后重命名的文件mownfish.log.2013-11-24是否存在，如果存在就删除\n3. 将目前的日志文件mownfish.log重命名为mownfish.log.2013-11-24\n4. 以“w”模式打开一个新文件mownfish.log。\n\n　　如果是多进程的应用程序，如tornado，将会出现异常。比如某个进程刚刚完成了第二步，将mownfish.log重命名为mownfish.log.2013-11-24。另外一个进程刚刚开始执行第二步，此时进程1还没有进行到第3步，即创建一个新的mownfish.log，所以进程2找不到mownfish.log，程序抛出异常。另外每次以W模式打开，也会使新生成的mownfish.log文件内容被重复的清除多次。\n　　解决方案为创建类，继承自TimedRotatingHandler，重写其切分方法doRollover()方法。流程修改为：\n1. 判断切分后重命名的文件mownfish.log.2013-11-24是否存在，如不存在将日志文件mownfish.log重命名为mownfish.log.2013-11-24\n2. 以’a‘模式打开文件mownfish.log\n\n　　这样当进程1重命名之后，进程2就不会重复执行重命名的动作了。\n```Python\ndef doRollover(self):\n    \"\"\"\n    do a rollover; in this case, a date/time stamp is appended to the filename\n    when the rollover happens.  However, you want the file to be named for the\n    start of the interval, not the current time.  If there is a backup count,\n    then we have to get a list of matching filenames, sort them and remove\n    the one with the oldest suffix.\n    \"\"\"\n    if self.stream:\n        self.stream.close()\n    # get the time that this sequence started at and make it a TimeTuple\n    t = self.rolloverAt - self.interval\n    if self.utc:\n        timeTuple = time.gmtime(t)\n    else:\n        timeTuple = time.localtime(t)\n    dfn = self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)\n    #if os.path.exists(dfn):\n    #    os.remove(dfn)\n    if not os.path.exists(dfn):\n        os.rename(self.baseFilename, dfn)\n    if self.backupCount > 0:\n        # find the oldest log file and delete it\n        #s = glob.glob(self.baseFilename + \".20*\")\n        #if len(s) > self.backupCount:\n        #    s.sort()\n        #    os.remove(s[0])\n        for s in self.getFilesToDelete():\n            os.remove(s)\n    #print \"%s -> %s\" % (self.baseFilename, dfn)\n    self.mode = 'a'\n    self.stream = self._open()\n    currentTime = int(time.time())\n    newRolloverAt = self.computeRollover(currentTime)\n    while newRolloverAt <= currentTime:\n        newRolloverAt = newRolloverAt + self.interval\n    #If DST changes and midnight or weekly rollover, adjust for this.\n    if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n        dstNow = time.localtime(currentTime)[-1]\n        dstAtRollover = time.localtime(newRolloverAt)[-1]\n        if dstNow != dstAtRollover:\n            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                newRolloverAt = newRolloverAt - 3600\n            else:           # DST bows out before next rollover, so we need to add an hour\n                newRolloverAt = newRolloverAt + 3600\n    self.rolloverAt = newRolloverAt\n```\n","slug":"Python多进程log日志切分错误的解决方案","published":1,"updated":"2016-01-27T03:23:01.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxff800110qi5ucw0cdve","sticky":0},{"title":"OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user data","date":"2012-10-31T03:26:13.000Z","_content":"　　最近几天因为系统定制化的需求，集中研究了一下OpenStack的user_data的相关细节OpenStack虚拟机的用户客制化方法（User Data），上一遍博文最后提到了只成功测试了ubuntu的cloudimage，而自己用mirrors上下载的iso镜像创建image后即使安装了cloud-init这个包，也会出现诸如在OpenStackdashboard中创建虚拟机时所填的主机名并未导入，user_data不可用等问题，查看cloud-init的log会显示。\n<!--more-->\n\n```Bash\n2012-10-30 14:57:43,189 - cloud-init[INFO]:cloud-init start running: Tue, 30 Oct 2012 06:57:43 +0000. up 6.99seconds\n2012-10-30 14:57:43,249 - __init__.py[DEBUG]: searching for datasource in ['DataSourceNoCloudNet', 'DataSourceConfigDriveNet','DataSourceOVFNet', 'DataSourceMAAS']\n2012-10-30 14:57:43,269 - __init__.py[DEBUG]: Did not find datasource. searched classes: ['DataSourceNoCloudNet','DataSourceConfigDriveNet', 'DataSourceOVFNet','DataSourceMAAS']\n```\n　　而正常的log应该会显示\n```Bash\n2012-10-31 10:56:38,008 - cloud-init[INFO]: cloud-init startrunning: Wed, 31 Oct 2012 02:56:37 +0000. up 8.83 seconds\n2012-10-31 10:56:38,050 - __init__.py[DEBUG]: searching for datasource in ['DataSourceNoCloudNet', 'DataSourceOVFNet','DataSourceEc2']\n2012-10-31 10:56:53,270 - DataSourceEc2.py[DEBUG]: Using metadatasource: 'http://169.254.169.254'\n2012-10-31 10:56:53,329 - DataSourceEc2.py[DEBUG]: crawl ofmetadata service took 0s\n2012-10-31 10:56:53,329 - __init__.py[DEBUG]: found data sourceDataSourceEc2\n```\n　　日志显示找不到meadata source 169.254.169.254，这是一个内部的local source\n昨晚在网上查找了大量资料，发现有关cloud-init的资料比较少，最后在rackspace的网站上发现了一份编辑镜像的代码，终于找到了方法。\n　　按照OpenStack创建ubuntu镜像的官方文档，我们在安装系统后仅仅需要\n```Bash\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install openssh-server cloud-init\n#Remove the network persistence rules from /etc/udev/rules.das their presence will result in\n#the network interface in the instance coming up as an interfaceother than eth0.\nsudo rm -rf /etc/udev/rules.d/70-persistent-net.rules\n```\n　　然后实际上cloud-init包的安装是需要配置的，配置方法为\n```Bash\necho \"cloud-init cloud-init/datasources string NoCloud, OVF,Ec2\" >\n/tmp/debconf-selections\n/usr/bin/debconf-set-selections /tmp/debconf-selections\nrm -f /tmp/debconf-selections\napt-get -y install cloud-init\n```\n　　debconf-set-selections命令可以在包安装的时候对包进行必要的配置，配置参数NoCloud表示instance运行在一个简单的没有metadata服务的系统上，boot是后连接系统的local metadata sourcehttp://169.254.169.254:80。进行上述配置后，重新制作镜像，上述问题经试验一切正常。\n***\n　　稍后可能在研究下CentOS和Fedora上的解决方法供大家参考。 \n","source":"_posts/OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user-data.md","raw":"title: OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user data\ndate: 2012-10-31 11:26:13\ntags: [OpenStack, cloud-init]\n---\n　　最近几天因为系统定制化的需求，集中研究了一下OpenStack的user_data的相关细节OpenStack虚拟机的用户客制化方法（User Data），上一遍博文最后提到了只成功测试了ubuntu的cloudimage，而自己用mirrors上下载的iso镜像创建image后即使安装了cloud-init这个包，也会出现诸如在OpenStackdashboard中创建虚拟机时所填的主机名并未导入，user_data不可用等问题，查看cloud-init的log会显示。\n<!--more-->\n\n```Bash\n2012-10-30 14:57:43,189 - cloud-init[INFO]:cloud-init start running: Tue, 30 Oct 2012 06:57:43 +0000. up 6.99seconds\n2012-10-30 14:57:43,249 - __init__.py[DEBUG]: searching for datasource in ['DataSourceNoCloudNet', 'DataSourceConfigDriveNet','DataSourceOVFNet', 'DataSourceMAAS']\n2012-10-30 14:57:43,269 - __init__.py[DEBUG]: Did not find datasource. searched classes: ['DataSourceNoCloudNet','DataSourceConfigDriveNet', 'DataSourceOVFNet','DataSourceMAAS']\n```\n　　而正常的log应该会显示\n```Bash\n2012-10-31 10:56:38,008 - cloud-init[INFO]: cloud-init startrunning: Wed, 31 Oct 2012 02:56:37 +0000. up 8.83 seconds\n2012-10-31 10:56:38,050 - __init__.py[DEBUG]: searching for datasource in ['DataSourceNoCloudNet', 'DataSourceOVFNet','DataSourceEc2']\n2012-10-31 10:56:53,270 - DataSourceEc2.py[DEBUG]: Using metadatasource: 'http://169.254.169.254'\n2012-10-31 10:56:53,329 - DataSourceEc2.py[DEBUG]: crawl ofmetadata service took 0s\n2012-10-31 10:56:53,329 - __init__.py[DEBUG]: found data sourceDataSourceEc2\n```\n　　日志显示找不到meadata source 169.254.169.254，这是一个内部的local source\n昨晚在网上查找了大量资料，发现有关cloud-init的资料比较少，最后在rackspace的网站上发现了一份编辑镜像的代码，终于找到了方法。\n　　按照OpenStack创建ubuntu镜像的官方文档，我们在安装系统后仅仅需要\n```Bash\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install openssh-server cloud-init\n#Remove the network persistence rules from /etc/udev/rules.das their presence will result in\n#the network interface in the instance coming up as an interfaceother than eth0.\nsudo rm -rf /etc/udev/rules.d/70-persistent-net.rules\n```\n　　然后实际上cloud-init包的安装是需要配置的，配置方法为\n```Bash\necho \"cloud-init cloud-init/datasources string NoCloud, OVF,Ec2\" >\n/tmp/debconf-selections\n/usr/bin/debconf-set-selections /tmp/debconf-selections\nrm -f /tmp/debconf-selections\napt-get -y install cloud-init\n```\n　　debconf-set-selections命令可以在包安装的时候对包进行必要的配置，配置参数NoCloud表示instance运行在一个简单的没有metadata服务的系统上，boot是后连接系统的local metadata sourcehttp://169.254.169.254:80。进行上述配置后，重新制作镜像，上述问题经试验一切正常。\n***\n　　稍后可能在研究下CentOS和Fedora上的解决方法供大家参考。 \n","slug":"OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入user-data","published":1,"updated":"2016-01-20T04:31:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxffd00170qi5jfzwbvx3","sticky":0},{"title":"OpenStack虚拟机的用户客制化方法（User Data）","date":"2012-10-30T03:54:19.000Z","_content":"![盛大云的用户信息定制界面](http://7xpwqp.com1.z0.glb.clouddn.com/2012-10-30-01.jpg)\n　　很多成熟的公有云产品在申请虚拟机资源的时候，都可以定制客制化的用户信息，如盛大云、阿里云等可以定制虚拟机的服务器名称，用户名及密码口令等。特别是用户口令，虽然OpenStack有非常成熟的公私钥KeyPairs登陆体系，但是对于国内大多开发者还是习惯于用户名口令的登陆方式。某些场景下，服务器管理员在客户现场需要对服务器进行某些简单操作，也许没有SSH环境等，这时如果通过VNC的方式就比较简单，然而KeyPair的登陆方式还不支持VNC模式。\n<!--more-->\n　　在服务器管理员需要使用用户名口令的方式进行登陆的模式下，如果能让用户自己定义用户名口令可以提高一定的安全等级，增加用户对产品的认知和信任度。\n　　在OpenStack中，我们通过user-data功能实现客户信息的定制，可以对虚拟机进行许多初始化的操作如设定语言区域，设定主机名称，生成SSH密钥，设定挂载节点等。\n　　通过研究ubuntucloud-init和AWS的相关文档，user-data的设置可以支持有以下几种脚本语言：\n* Gzip Compressed Content\ncontent found to be gzip compressed will be uncompressed.\nTheuncompressed data will then be used as if it were not\ncompressed.Compression of data is useful because user-data is\nlimited to 16384bytes1\n* Mime Multi Part archive\nThis list of rules is applied to each part ofthis multi-part\nfile. Using a mime-multi part file, the user canspecify more than\none type of data. For example, both a user datascript and a\ncloud-config type could be specified.\n* User-Data Script\nbegins with: \"#!\" or\"Content-Type: text/x-shellscript\" \nscript will be executed at \"rc.local-like\" level during first boot.rc.local-like means \"very late in the boot sequence\"\n* Include File\nbegins with \"#include\" or\"Content-Type: text/x-include-url\" \nThis content is a \"include\" file. The file contains a list of urls,one per line. Each of the URLs will be read, and their content willbe passed through this same set of rules. Ie, the content read fromthe URL can be gzipped, mime-multi-part, or plain text\n* Cloud Config Data\nbegins with \"#cloud-config\" or\"Content-Type: text/cloud-config\"\nThis content is \"cloud-config\" data. See the examples for acommented example of supported config formats.\n* Upstart Job\nbegins with \"#upstart-job\" or\"Content-Type: text/upstart-job\"\nContent is placed into a file in /etc/init, and will be consumed byupstart as any other upstart job.\n* Cloud Boothook\nbegins with \"#cloud-boothook\" or\"Content-Type: text/cloud-boothook\"\nThis content is \"boothook\" data. It is stored in a file under/var/lib/cloud and then executed immediately.\nThis is the earliest \"hook\" available. Note, that there is nomechanism provided for running only once. The boothook must takecare of this itself. It is provided with the instance id in theenvironment variable \"INSTANCE_ID\". This could be made use of toprovide a 'once-per-instance'\nOnly available in 10.10 or later (cloud-init 0.5.12 andlater)\n* Part Handler\nbegins with \"#part-handler\" or\"Content-Type: text/part-handler\"\nThis is a 'part-handler'. It will be written to a file in/var/lib/cloud/data based on its filename. This must be python codethat contains a list_types method and a handle_type method.\nOncethe section is read the 'list_types' method will be called. It mustreturn a list of mime-types that this part-handler handlers.\nThe 'handle_type' method must be like:\n```Python\ndef handle_part(data,ctype,filename,payload):\n# data = the cloudinit object\n# ctype = \"__begin__\", \"__end__\", or the mime-type of the part that is\n# being handled.\n# filename = the filename of the part (or a generated filename if none is\n# present in mime data)# payload = the parts' content\n```\n\n　　这里主要关注User-Data Script，其使用的就是常用的shell脚本，我们只要在dashboard创建虚拟机的时候讲脚本写入user data输入框中即可。\n![user-data sample](http://7xpwqp.com1.z0.glb.clouddn.com/2012-10-30-02.png)\n　　目前还仅仅测试了ubuntu的cloudimage，非UEC镜像即使按照installturtion安装了cloud-init包也没有测试成功，还在查找原因，后面弄好了会接着给大家介绍。\n\n***\n\n　　非UEC镜像的问题实际上是cloud-init这个包的安装需要进行配置，详见OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入userdata。\n","source":"_posts/OpenStack虚拟机的用户客制化方法（User-Data）.md","raw":"title: OpenStack虚拟机的用户客制化方法（User Data）\ndate: 2012-10-30 11:54:19\ntags: [OpenStack, Nova]\n---\n![盛大云的用户信息定制界面](http://7xpwqp.com1.z0.glb.clouddn.com/2012-10-30-01.jpg)\n　　很多成熟的公有云产品在申请虚拟机资源的时候，都可以定制客制化的用户信息，如盛大云、阿里云等可以定制虚拟机的服务器名称，用户名及密码口令等。特别是用户口令，虽然OpenStack有非常成熟的公私钥KeyPairs登陆体系，但是对于国内大多开发者还是习惯于用户名口令的登陆方式。某些场景下，服务器管理员在客户现场需要对服务器进行某些简单操作，也许没有SSH环境等，这时如果通过VNC的方式就比较简单，然而KeyPair的登陆方式还不支持VNC模式。\n<!--more-->\n　　在服务器管理员需要使用用户名口令的方式进行登陆的模式下，如果能让用户自己定义用户名口令可以提高一定的安全等级，增加用户对产品的认知和信任度。\n　　在OpenStack中，我们通过user-data功能实现客户信息的定制，可以对虚拟机进行许多初始化的操作如设定语言区域，设定主机名称，生成SSH密钥，设定挂载节点等。\n　　通过研究ubuntucloud-init和AWS的相关文档，user-data的设置可以支持有以下几种脚本语言：\n* Gzip Compressed Content\ncontent found to be gzip compressed will be uncompressed.\nTheuncompressed data will then be used as if it were not\ncompressed.Compression of data is useful because user-data is\nlimited to 16384bytes1\n* Mime Multi Part archive\nThis list of rules is applied to each part ofthis multi-part\nfile. Using a mime-multi part file, the user canspecify more than\none type of data. For example, both a user datascript and a\ncloud-config type could be specified.\n* User-Data Script\nbegins with: \"#!\" or\"Content-Type: text/x-shellscript\" \nscript will be executed at \"rc.local-like\" level during first boot.rc.local-like means \"very late in the boot sequence\"\n* Include File\nbegins with \"#include\" or\"Content-Type: text/x-include-url\" \nThis content is a \"include\" file. The file contains a list of urls,one per line. Each of the URLs will be read, and their content willbe passed through this same set of rules. Ie, the content read fromthe URL can be gzipped, mime-multi-part, or plain text\n* Cloud Config Data\nbegins with \"#cloud-config\" or\"Content-Type: text/cloud-config\"\nThis content is \"cloud-config\" data. See the examples for acommented example of supported config formats.\n* Upstart Job\nbegins with \"#upstart-job\" or\"Content-Type: text/upstart-job\"\nContent is placed into a file in /etc/init, and will be consumed byupstart as any other upstart job.\n* Cloud Boothook\nbegins with \"#cloud-boothook\" or\"Content-Type: text/cloud-boothook\"\nThis content is \"boothook\" data. It is stored in a file under/var/lib/cloud and then executed immediately.\nThis is the earliest \"hook\" available. Note, that there is nomechanism provided for running only once. The boothook must takecare of this itself. It is provided with the instance id in theenvironment variable \"INSTANCE_ID\". This could be made use of toprovide a 'once-per-instance'\nOnly available in 10.10 or later (cloud-init 0.5.12 andlater)\n* Part Handler\nbegins with \"#part-handler\" or\"Content-Type: text/part-handler\"\nThis is a 'part-handler'. It will be written to a file in/var/lib/cloud/data based on its filename. This must be python codethat contains a list_types method and a handle_type method.\nOncethe section is read the 'list_types' method will be called. It mustreturn a list of mime-types that this part-handler handlers.\nThe 'handle_type' method must be like:\n```Python\ndef handle_part(data,ctype,filename,payload):\n# data = the cloudinit object\n# ctype = \"__begin__\", \"__end__\", or the mime-type of the part that is\n# being handled.\n# filename = the filename of the part (or a generated filename if none is\n# present in mime data)# payload = the parts' content\n```\n\n　　这里主要关注User-Data Script，其使用的就是常用的shell脚本，我们只要在dashboard创建虚拟机的时候讲脚本写入user data输入框中即可。\n![user-data sample](http://7xpwqp.com1.z0.glb.clouddn.com/2012-10-30-02.png)\n　　目前还仅仅测试了ubuntu的cloudimage，非UEC镜像即使按照installturtion安装了cloud-init包也没有测试成功，还在查找原因，后面弄好了会接着给大家介绍。\n\n***\n\n　　非UEC镜像的问题实际上是cloud-init这个包的安装需要进行配置，详见OpenStack解决非UEC镜像的虚拟机cloud-init不工作不能自动修改主机名称不能注入userdata。\n","slug":"OpenStack虚拟机的用户客制化方法（User-Data）","published":1,"updated":"2016-01-20T04:28:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxffh001c0qi5shzukqjg","sticky":0},{"title":"OpenStack基础组件kombu杂谈","date":"2013-12-18T01:36:53.000Z","_content":"&emsp;&emsp;作为一个典型的分布式系统，OpenStack的各模块之间也需要进行大量的消息传递。OpenStack采用的是AMQP的消息队列方案。\n&emsp;&emsp;AMQP是一个广泛使用的消息队列的规范。服务端常采用的是RabbitMQ（在AMQP的规范中，消息队列的服务端被成为broker），现在已收归vmware麾下，使用erlang实现。OpenStack除了支持RabbitMQ之外，还支持apache上开源的Qpid。Qpid有C++和java两种broker的实现。\n>kombu是AMQP协议client端的一个python实现。另有比较常用的有如pika，py-amqplib等。\n<!--more-->\n&emsp;&emsp;kombu的特点是支持多种的符合APMQ协议的消息队列系统。不仅支持原生的AMQP消息队列如RabbitMQ、Qpid，还支持虚拟的消息队列如redis、mongodb、beantalk、couchdb、in-memory等。我认为OpenStack使用kombu作为消息队列使用的client库而没有用广泛使用的pika库有两个原因：\n1. kombu除了支持纯AMQP的实现还支持虚拟AMQP的实现作为消息队列系统，如redis、mongodb、beantalk等。众所周知，OpenStack的设计理念及思想为各个组件可以方便的替换、组合，这样用kombu就有了极大的方便，使用者可以依据需要，方便的使用redis等搭建一个openstack的消息系统。\n```Python\n# Using pyamqp\namqp://guest:guest@localhost:5672/\n\n# Using Redis\nredis://localhost:6379/\n\n# Using Redis over a Unix socket\nredis+socket:///tmp/redis.sock\n\n# Using virtual host '/foo'\namqp://localhost//foo\n```\n2. kombu可以通过配置设置AMQP连接的底层库，librabbitmq或者pyamqp。前者是一个python嫁接C库的实现，后者是一个纯python的实现。openstack内部使用的是eventlet的框架，一个基于python协程的异步网络框架。其核心是通过greenlet的monkeypath将涉及网络IO的python模块进行绿化（协程化）。所以如果用纯python实现的AMQP库，就可以应用eventlet的框架将设计网络IO的部分变为协程，提高整体的网络IO性能。\n\n    __生产者：__\n```Python\nfrom kombu import Connection, Exchange, Queue\n\nmedia_exchange = Exchange('media', 'direct', durable=True)\nvideo_queue = Queue('video', exchange=media_exchange, routing_key='video')\n\n\n# connections\nwith Connection('amqp://guest:guest@localhost//') as conn:\n\n    # produce\n    producer = conn.Producer(serializer='json')\n    producer.publish({'name': '/tmp/lolcat1.avi', 'size': 1301013},\n                    exchange=media_exchange,\n                    routing_key='video',\n                    declare=[video_queue])\n\n    # the declare above, makes sure the video queue is declared\n    # so that the messages can be delivered.\n    # It's a best practice in Kombu to have both\n    # publishers and\n    # consumers declare the queue.  You can also\n    # declare the\n    # queue manually using:\n    #     video_queue(conn).declare()\n```\n    __消费者：__\n```Python\nfrom kombu import Connection, Exchange, Queue\n\nmedia_exchange = Exchange('media', 'direct', durable=True)\nvideo_queue = Queue('video', exchange=media_exchange, routing_key='video')\n\ndef process_media(body, message):\n    print body\n        message.ack()\n# connections\nwith Connection('amqp://guest:guest@localhost//') as conn:\n    # consume\n    with conn.Consumer(video_queue, callbacks=[process_media]) as consumer:\n        # Process messages and handle events on all channels\n        while True:\n            conn.drain_events()\n```\n","source":"_posts/OpenStack基础组件kombu杂谈.md","raw":"title: OpenStack基础组件kombu杂谈\ndate: 2013-12-18 09:36:53\ntags: [OpenStack, AMQP, kombu]\n---\n&emsp;&emsp;作为一个典型的分布式系统，OpenStack的各模块之间也需要进行大量的消息传递。OpenStack采用的是AMQP的消息队列方案。\n&emsp;&emsp;AMQP是一个广泛使用的消息队列的规范。服务端常采用的是RabbitMQ（在AMQP的规范中，消息队列的服务端被成为broker），现在已收归vmware麾下，使用erlang实现。OpenStack除了支持RabbitMQ之外，还支持apache上开源的Qpid。Qpid有C++和java两种broker的实现。\n>kombu是AMQP协议client端的一个python实现。另有比较常用的有如pika，py-amqplib等。\n<!--more-->\n&emsp;&emsp;kombu的特点是支持多种的符合APMQ协议的消息队列系统。不仅支持原生的AMQP消息队列如RabbitMQ、Qpid，还支持虚拟的消息队列如redis、mongodb、beantalk、couchdb、in-memory等。我认为OpenStack使用kombu作为消息队列使用的client库而没有用广泛使用的pika库有两个原因：\n1. kombu除了支持纯AMQP的实现还支持虚拟AMQP的实现作为消息队列系统，如redis、mongodb、beantalk等。众所周知，OpenStack的设计理念及思想为各个组件可以方便的替换、组合，这样用kombu就有了极大的方便，使用者可以依据需要，方便的使用redis等搭建一个openstack的消息系统。\n```Python\n# Using pyamqp\namqp://guest:guest@localhost:5672/\n\n# Using Redis\nredis://localhost:6379/\n\n# Using Redis over a Unix socket\nredis+socket:///tmp/redis.sock\n\n# Using virtual host '/foo'\namqp://localhost//foo\n```\n2. kombu可以通过配置设置AMQP连接的底层库，librabbitmq或者pyamqp。前者是一个python嫁接C库的实现，后者是一个纯python的实现。openstack内部使用的是eventlet的框架，一个基于python协程的异步网络框架。其核心是通过greenlet的monkeypath将涉及网络IO的python模块进行绿化（协程化）。所以如果用纯python实现的AMQP库，就可以应用eventlet的框架将设计网络IO的部分变为协程，提高整体的网络IO性能。\n\n    __生产者：__\n```Python\nfrom kombu import Connection, Exchange, Queue\n\nmedia_exchange = Exchange('media', 'direct', durable=True)\nvideo_queue = Queue('video', exchange=media_exchange, routing_key='video')\n\n\n# connections\nwith Connection('amqp://guest:guest@localhost//') as conn:\n\n    # produce\n    producer = conn.Producer(serializer='json')\n    producer.publish({'name': '/tmp/lolcat1.avi', 'size': 1301013},\n                    exchange=media_exchange,\n                    routing_key='video',\n                    declare=[video_queue])\n\n    # the declare above, makes sure the video queue is declared\n    # so that the messages can be delivered.\n    # It's a best practice in Kombu to have both\n    # publishers and\n    # consumers declare the queue.  You can also\n    # declare the\n    # queue manually using:\n    #     video_queue(conn).declare()\n```\n    __消费者：__\n```Python\nfrom kombu import Connection, Exchange, Queue\n\nmedia_exchange = Exchange('media', 'direct', durable=True)\nvideo_queue = Queue('video', exchange=media_exchange, routing_key='video')\n\ndef process_media(body, message):\n    print body\n        message.ack()\n# connections\nwith Connection('amqp://guest:guest@localhost//') as conn:\n    # consume\n    with conn.Consumer(video_queue, callbacks=[process_media]) as consumer:\n        # Process messages and handle events on all channels\n        while True:\n            conn.drain_events()\n```\n","slug":"OpenStack基础组件kombu杂谈","published":1,"updated":"2016-01-20T04:28:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxffl001g0qi53k1c7zjd","sticky":0},{"title":"Linux的IO复用","date":"2013-03-11T06:29:20.000Z","_content":"首先我们来定义流的概念，一个流可以是文件，socket，pipe等等可以进行I/O操作的内核对象。不管是文件，还是套接字，还是管道，我们都可以把他们看作流。\n<!--more-->\n之后我们来讨论I/O的操作，通过read，我们可以从流中读入数据；通过write，我们可以往流写入数据。现在假定一个情形，我们需要从流中读数据，但是流中还没有数据，（典型的例子为，客户端要从socket读如数据，但是服务器还没有把数据传回来），这时候该怎么办？\n阻塞：阻塞是个什么概念呢？比如某个时候你在等快递，但是你不知道快递什么时候过来，而且你没有别的事可以干（或者说接下来的事要等快递来了才能做）；那么你可以去睡觉了，因为你知道快递把货送来时一定会给你打个电话（假定一定能叫醒你）。\n非阻塞忙轮询：接着上面等快递的例子，如果用忙轮询的方法，那么你需要知道快递员的手机号，然后每分钟给他挂个电话：“你到了没？”\n很明显一般人不会用第二种做法，不仅显很无脑，浪费话费不说，还占用了快递员大量的时间。\n大部分程序也不会用第二种做法，因为第一种方法经济而简单，经济是指消耗很少的CPU时间，如果线程睡眠了，就掉出了系统的调度队列，暂时不会去瓜分CPU宝贵的时间片了。\n为了了解阻塞是如何进行的，我们来讨论缓冲区，以及内核缓冲区，最终把I/O事件解释清楚。缓冲区的引入是为了减少频繁I/O操作而引起频繁的系统调用（你知道它很慢的），当你操作一个流时，更多的是以缓冲区为单位进行操作，这是相对于用户空间而言。对于内核来说，也需要缓冲区。\n假设有一个管道，进程A为管道的写入方，Ｂ为管道的读出方。\n假设一开始内核缓冲区是空的，B作为读出方，被阻塞着。然后首先A往管道写入，这时候内核缓冲区由空的状态变到非空状态，内核就会产生一个事件告诉Ｂ该醒来了，这个事件姑且称之为“缓冲区非空”。\n但是“缓冲区非空”事件通知B后，B却还没有读出数据；且内核许诺了不能把写入管道中的数据丢掉这个时候，Ａ写入的数据会滞留在内核缓冲区中，如果内核也缓冲区满了，B仍未开始读数据，最终内核缓冲区会被填满，这个时候会产生一个I/O事件，告诉进程A，你该等等（阻塞）了，我们把这个事件定义为“缓冲区满”。\n假设后来Ｂ终于开始读数据了，于是内核的缓冲区空了出来，这时候内核会告诉A，内核缓冲区有空位了，你可以从长眠中醒来了，继续写数据了，我们把这个事件叫做“缓冲区非满”\n也许事件Y1已经通知了A，但是A也没有数据写入了，而Ｂ继续读出数据，知道内核缓冲区空了。这个时候内核就告诉B，你需要阻塞了！，我们把这个时间定为“缓冲区空”。\n这四个情形涵盖了四个I/O事件，缓冲区满，缓冲区空，缓冲区非空，缓冲区非满（注都是说的内核缓冲区，且这四个术语都是我生造的，仅为解释其原理而造）。这四个I/O事件是进行阻塞同步的根本。（如果不能理解“同步”是什么概念，请学习操作系统的锁，信号量，条件变量等任务同步方面的相关知识）。\n然后我们来说说阻塞I/O的缺点。但是阻塞I/O模式下，一个线程只能处理一个流的I/O事件。如果想要同时处理多个流，要么多进程(fork)，要么多线程(pthread_create)，很不幸这两种方法效率都不高。\n于是再来考虑非阻塞忙轮询的I/O方式，我们发现我们可以同时处理多个流了（把一个流从阻塞模式切换到非阻塞模式再此不予讨论）：\n```C\nwhile true {\n    for i in stream[]; {\n        if i has data\n            read until unavailable\n    }\n}\n```\n我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。这里要补充一点，阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象（后文介绍的select以及epoll）处理甚至直接忽略。\n为了避免CPU空转，可以引进了一个代理（一开始有一位叫做select的代理，后来又有一位叫做poll的代理，不过两者的本质是一样的）。这个代理比较厉害，可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流（于是我们可以把“忙”字去掉了）。代码长这样:\n```C\nwhile true {\n    select(streams[])\n    for i in streams[] {\n        if i has data\n            read until unavailable\n    }\n}\n```\n于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。\n但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，没一次无差别轮询时间就越长。再次说了这么多，终于能好好解释epoll了。epoll可以理解为event\npoll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）\n在讨论epoll的实现细节之前，先把epoll的相关操作列出：\n```C\nepoll_create 创建一个epoll对象，一般epollfd = epoll_create()\n\nepoll_ctl\n（epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件\n比如\nepoll_ctl(epollfd, EPOLL_CTL_ADD, socket,\nEPOLLIN);//注册缓冲区非空事件，即有数据流入\nepoll_ctl(epollfd, EPOLL_CTL_DEL, socket,\nEPOLLOUT);//注册缓冲区非满事件，即流可以被写入\nepoll_wait(epollfd,...)等待直到注册的事件发生\n（注：当对一个非阻塞流的读写发生缓冲区满或缓冲区空，write/read会返回-1，并设置errno=EAGAIN。而epoll只关心缓冲区非满和缓冲区非空事件）。\n\n一个epoll模式的代码大概的样子是：\nwhile true {\n    active_stream[] = epoll_wait(epollfd)\n    for i in active_stream[] {\n        read or write till\n    }\n}\n```\n因为需要了解底层设备访问的原理，所以惯用高层应用语言的我，需要了解一下Linux的设备访问机制，尤其是处理一组非阻塞IO的原理方法，标准的术语好像是叫多路复用。以下文章部分句子有引用之处，恕没有一一指出出处。\n对于接触过Linux内核或设备驱动开发的读者，一定清楚poll和select系统调用，以及从2.5版本引入的epoll机制（epoll机制包含三个系统调用）。网上关于它们的文章，有说用法的，甚为详细，更有分析源代码的，又比较深入，且枝节颇多。经过几篇文章的阅读，我把觉得比较核心的东西写下来吧。我的用意是尽可能以简单的概念，比对他们三者的异同。\n几经查找我才确定下来，poll和select应该被归类为这样的系统调用，它们可以阻塞地同时探测一组支持非阻塞的IO设备，是否有事件发生（如可读，可写，有高优先级的错误输出，出现错误等等），直至某一个设备触发了事件或者超过了指定的等待时间——也就是它们的职责不是做IO，而是帮助调用者寻找当前就绪的设备。同类型的产品是Windows的IOCP，它也是处理多路复用，只是把IO和探测封装在了一起了。\n准备的知识有两点：1、fd；2、op->poll。做IO，而是帮助调用者寻找当前就绪的设备。同类型的产品是Windows的IOCP，它也是处簱绪时调用的回调函数，这个函数是把设备自己特有的等待队列传给内核，让内核把当前的进程挂载到其中（因为当设备就绪时，设备就应该去唤醒在自己特有等待队列中的所有节点，这样当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本poll和select。\n本质而言，poll和select的共同点就是，对全部指定设备做一次poll，当然这往往都是还没有就绪的，那就会通过回调函数把当前进程注册到设备的等待队列，如果所有设备返回的掩码都没有显示任何的事件触发，就去掉回调函数的函数指针，进入有限时的睡眠状态，再恢复和不断做poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用返回，回到用户态，用户堷当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事件触发，就去掉回调函数的函数指针，进入有限时的睡眠状态，再恢复和不断做poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用返回，回到用户态，用户堷当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发畿须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本敄掩码都没件，如输入信道期待输入就绪，输入挂起和错误等事件。\n然后，select就挑选调用者关心的fd做poll文件操作，检测返回的掩码，看看是否有fdæ\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事件触发，就去掉回调函数的函数¼poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用º件判断规则的fd，采用了位图的方式表示，一眉事件触发为止。只要有事件触发，系统调用¯的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就¶©期多路复用的版本敄掩码都没件，如输入信道期待输入就绪，输入挂起和错误等事件。\n然后，select就挑选调用者关心的fd做poll文件操作，检测返回的掩码，看看是否有fdæ\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事ä包含的除了fd，还有期待的事件掩码和返回的事件掩码，实质上就是将select的中的fd，传入和传出参数归到一个结构之下，也不再把fd分为三组，也不再硬性规定fd感兴趣的事件，这由调用者自己设定。这样，不使用位图来组织数据，也就不需要位图的全部遍历了。按照一般队列地遍历，每个fd做poll文件操作，检查返回的掩码是否有期待的事件，以及做是否有挂起和错误的必要性检查，如果有事件触发，就可以返回调用了。\n回到poll和select的共同点，面对高并发多连接的应用情境，它们显现出原来没有考虑到的不足，虽然poll比起select又有所改进了。除了上述的关于每次调用都需要做一次从用户空间到内核空间的拷贝，还有这样的问题，就是当处于这样的应用情境时，poll和select会不得不多次操作，并且每次操作都很有可能需要多次进入睡眠状态，也就是多次全部轮询fd，我们应该怎么处理一些会出现重复而无意义的操作。\n这些重复而无意义的操作有：1、从用户到内核空间拷贝，既然长期监视这几个fd，甚至连期待的事件也不会改变，那拷贝无疑就是重复而无意义的，我们可以让内核长期保存所有需要监视的fd甚至期待事件，或者可以再需要时对部分期待事件进行修改；2、将当前线程轮流加入到每个fd对应设备的等待队列，这样做无非是哪一个设备就绪时能够通知进程退出调用，聪明的开发者想到，那就找个“代理”的回调函数，代替当前进程加入fd的等待队列好了（这也是我后来才总结出来，Linux的等待队列，实质上是回调函数队列吧，也可以使用宏来将当前进程“加入”等待队列，其实就是将唤醒当前进程的回调函数加入队列）。这样，像poll系统调用一样，做poll文件操作发现尚未就绪时，它就调用传入的一个回调函数，这是epoll指定的回调函数，它不再像以前的poll系统调用指定的回调函数那样，而是就将那个“代理”的回调函数加入设备的等待队列就好了，这个代理的回调函数就自己乖乖地等待设备就绪时将它唤醒，然后它就把这个设备fd放到一个指定的地方，同时唤醒可能在等待的进程，到这个指定的地方取fd就好了。我们把1和2结合起来就可以这样做了，只拷贝一次fd，一旦确定了fd就可以做poll文件操作，如果有事件当然好啦，马上就把fd放到指定的地方，而通常都是没有的，那就给这个fd的等待队列加一个回调函数，有事件就自动把fd放到指定的地方，当前进程不需要再一个个poll和睡眠等待了。\nepoll机制就是这样改进的了。诚然，fd少的时候，当前进程一个个地等问题不大，可是现在和尚多了，方丈就不好管了。以前设备事件触发时，只负责唤醒当前进程就好了，而当前进程也只能傻傻地在poll里面等待或者循环，再来一次poll，也不知道这个由设备提供的poll性能如何，能不能检查出当前进程已经在等待了就立即返回，当然，我也不明白为什么做了一遍的poll之后，去掉回调函数指针了，还得再做，不是说好了会去唤醒进程的吗？\n现在就让事件触发回调函数多做一步。本来设备还没就绪就调用一个回调函数了，现在再在这个回调函数里面做一个注册另一个回调函数的操作，目的就是使得设备事件触发多走一步，不仅仅是唤醒当前进程，还要把自己的fd放到指定的地方。就像收本子的班长，以前得一个个学生地去问有没有本子，如果没有，它还得等待一段时间而后又继续问，现在好了，只走一次，如果没有本子，班长就告诉大家去那里交本子，当班长想起要取本子，就去那里看看或者等待一定时间后离开，有本子到了就叫醒他，然后取走。这个道理很简单，就是老师和班干们常说的，大家多做一点工作，我的工作就轻松很多了，尤其是需要管理的东西越来越多时。\n这种机制或者说模式，我想在Java的FutureTask里面应该也会用到的，一堆在线程池里面跑着的线程（当然这是任务，不是线程，接口是Callable<V>，不是Runnable.run，是Callable.call，它是可以返回结果的），谁先做好就应该先处理呀，可是难道得一个个问吗？干脆就谁好了，谁就按照既定的操作暴露自己，这样FutureTask的get方法就可以马上知道当前最先完成的线程了，就可以取此线程返回结果了。\nepoll由三个系统调用组成，分别是epoll_create，epoll_ctl和epoll_wait。epoll_create用于创建和初始化一些内部使用的数据结构；epoll_ctl用于添加，删除或者修改指定的fd及其期待的事件，epoll_wait就是用于等待任何先前指定的fd事件。\n","source":"_posts/Linux的IO复用.md","raw":"title: Linux的IO复用\ndate: 2013-03-11 14:29:20\ntags: [IO复用, LINUX, 高并发]\n---\n首先我们来定义流的概念，一个流可以是文件，socket，pipe等等可以进行I/O操作的内核对象。不管是文件，还是套接字，还是管道，我们都可以把他们看作流。\n<!--more-->\n之后我们来讨论I/O的操作，通过read，我们可以从流中读入数据；通过write，我们可以往流写入数据。现在假定一个情形，我们需要从流中读数据，但是流中还没有数据，（典型的例子为，客户端要从socket读如数据，但是服务器还没有把数据传回来），这时候该怎么办？\n阻塞：阻塞是个什么概念呢？比如某个时候你在等快递，但是你不知道快递什么时候过来，而且你没有别的事可以干（或者说接下来的事要等快递来了才能做）；那么你可以去睡觉了，因为你知道快递把货送来时一定会给你打个电话（假定一定能叫醒你）。\n非阻塞忙轮询：接着上面等快递的例子，如果用忙轮询的方法，那么你需要知道快递员的手机号，然后每分钟给他挂个电话：“你到了没？”\n很明显一般人不会用第二种做法，不仅显很无脑，浪费话费不说，还占用了快递员大量的时间。\n大部分程序也不会用第二种做法，因为第一种方法经济而简单，经济是指消耗很少的CPU时间，如果线程睡眠了，就掉出了系统的调度队列，暂时不会去瓜分CPU宝贵的时间片了。\n为了了解阻塞是如何进行的，我们来讨论缓冲区，以及内核缓冲区，最终把I/O事件解释清楚。缓冲区的引入是为了减少频繁I/O操作而引起频繁的系统调用（你知道它很慢的），当你操作一个流时，更多的是以缓冲区为单位进行操作，这是相对于用户空间而言。对于内核来说，也需要缓冲区。\n假设有一个管道，进程A为管道的写入方，Ｂ为管道的读出方。\n假设一开始内核缓冲区是空的，B作为读出方，被阻塞着。然后首先A往管道写入，这时候内核缓冲区由空的状态变到非空状态，内核就会产生一个事件告诉Ｂ该醒来了，这个事件姑且称之为“缓冲区非空”。\n但是“缓冲区非空”事件通知B后，B却还没有读出数据；且内核许诺了不能把写入管道中的数据丢掉这个时候，Ａ写入的数据会滞留在内核缓冲区中，如果内核也缓冲区满了，B仍未开始读数据，最终内核缓冲区会被填满，这个时候会产生一个I/O事件，告诉进程A，你该等等（阻塞）了，我们把这个事件定义为“缓冲区满”。\n假设后来Ｂ终于开始读数据了，于是内核的缓冲区空了出来，这时候内核会告诉A，内核缓冲区有空位了，你可以从长眠中醒来了，继续写数据了，我们把这个事件叫做“缓冲区非满”\n也许事件Y1已经通知了A，但是A也没有数据写入了，而Ｂ继续读出数据，知道内核缓冲区空了。这个时候内核就告诉B，你需要阻塞了！，我们把这个时间定为“缓冲区空”。\n这四个情形涵盖了四个I/O事件，缓冲区满，缓冲区空，缓冲区非空，缓冲区非满（注都是说的内核缓冲区，且这四个术语都是我生造的，仅为解释其原理而造）。这四个I/O事件是进行阻塞同步的根本。（如果不能理解“同步”是什么概念，请学习操作系统的锁，信号量，条件变量等任务同步方面的相关知识）。\n然后我们来说说阻塞I/O的缺点。但是阻塞I/O模式下，一个线程只能处理一个流的I/O事件。如果想要同时处理多个流，要么多进程(fork)，要么多线程(pthread_create)，很不幸这两种方法效率都不高。\n于是再来考虑非阻塞忙轮询的I/O方式，我们发现我们可以同时处理多个流了（把一个流从阻塞模式切换到非阻塞模式再此不予讨论）：\n```C\nwhile true {\n    for i in stream[]; {\n        if i has data\n            read until unavailable\n    }\n}\n```\n我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。这里要补充一点，阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象（后文介绍的select以及epoll）处理甚至直接忽略。\n为了避免CPU空转，可以引进了一个代理（一开始有一位叫做select的代理，后来又有一位叫做poll的代理，不过两者的本质是一样的）。这个代理比较厉害，可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流（于是我们可以把“忙”字去掉了）。代码长这样:\n```C\nwhile true {\n    select(streams[])\n    for i in streams[] {\n        if i has data\n            read until unavailable\n    }\n}\n```\n于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。\n但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，没一次无差别轮询时间就越长。再次说了这么多，终于能好好解释epoll了。epoll可以理解为event\npoll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）\n在讨论epoll的实现细节之前，先把epoll的相关操作列出：\n```C\nepoll_create 创建一个epoll对象，一般epollfd = epoll_create()\n\nepoll_ctl\n（epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件\n比如\nepoll_ctl(epollfd, EPOLL_CTL_ADD, socket,\nEPOLLIN);//注册缓冲区非空事件，即有数据流入\nepoll_ctl(epollfd, EPOLL_CTL_DEL, socket,\nEPOLLOUT);//注册缓冲区非满事件，即流可以被写入\nepoll_wait(epollfd,...)等待直到注册的事件发生\n（注：当对一个非阻塞流的读写发生缓冲区满或缓冲区空，write/read会返回-1，并设置errno=EAGAIN。而epoll只关心缓冲区非满和缓冲区非空事件）。\n\n一个epoll模式的代码大概的样子是：\nwhile true {\n    active_stream[] = epoll_wait(epollfd)\n    for i in active_stream[] {\n        read or write till\n    }\n}\n```\n因为需要了解底层设备访问的原理，所以惯用高层应用语言的我，需要了解一下Linux的设备访问机制，尤其是处理一组非阻塞IO的原理方法，标准的术语好像是叫多路复用。以下文章部分句子有引用之处，恕没有一一指出出处。\n对于接触过Linux内核或设备驱动开发的读者，一定清楚poll和select系统调用，以及从2.5版本引入的epoll机制（epoll机制包含三个系统调用）。网上关于它们的文章，有说用法的，甚为详细，更有分析源代码的，又比较深入，且枝节颇多。经过几篇文章的阅读，我把觉得比较核心的东西写下来吧。我的用意是尽可能以简单的概念，比对他们三者的异同。\n几经查找我才确定下来，poll和select应该被归类为这样的系统调用，它们可以阻塞地同时探测一组支持非阻塞的IO设备，是否有事件发生（如可读，可写，有高优先级的错误输出，出现错误等等），直至某一个设备触发了事件或者超过了指定的等待时间——也就是它们的职责不是做IO，而是帮助调用者寻找当前就绪的设备。同类型的产品是Windows的IOCP，它也是处理多路复用，只是把IO和探测封装在了一起了。\n准备的知识有两点：1、fd；2、op->poll。做IO，而是帮助调用者寻找当前就绪的设备。同类型的产品是Windows的IOCP，它也是处簱绪时调用的回调函数，这个函数是把设备自己特有的等待队列传给内核，让内核把当前的进程挂载到其中（因为当设备就绪时，设备就应该去唤醒在自己特有等待队列中的所有节点，这样当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本poll和select。\n本质而言，poll和select的共同点就是，对全部指定设备做一次poll，当然这往往都是还没有就绪的，那就会通过回调函数把当前进程注册到设备的等待队列，如果所有设备返回的掩码都没有显示任何的事件触发，就去掉回调函数的函数指针，进入有限时的睡眠状态，再恢复和不断做poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用返回，回到用户态，用户堷当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事件触发，就去掉回调函数的函数指针，进入有限时的睡眠状态，再恢复和不断做poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用返回，回到用户态，用户堷当前进程就获取了完成的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发畿须是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发）。\n再谈谈早期多路复用的版本敄掩码都没件，如输入信道期待输入就绪，输入挂起和错误等事件。\n然后，select就挑选调用者关心的fd做poll文件操作，检测返回的掩码，看看是否有fdæ\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事件触发，就去掉回调函数的函数¼poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。只要有事件触发，系统调用º件判断规则的fd，采用了位图的方式表示，一眉事件触发为止。只要有事件触发，系统调用¯的信号了）。poll文件操作返回的必须是一组标准的掩码，其中的各个位指示当前的不同的就¶©期多路复用的版本敄掩码都没件，如输入信道期待输入就绪，输入挂起和错误等事件。\n然后，select就挑选调用者关心的fd做poll文件操作，检测返回的掩码，看看是否有fdæ\n再谈谈早期多路复用的版本敄掩码都没有显示任何的事ä包含的除了fd，还有期待的事件掩码和返回的事件掩码，实质上就是将select的中的fd，传入和传出参数归到一个结构之下，也不再把fd分为三组，也不再硬性规定fd感兴趣的事件，这由调用者自己设定。这样，不使用位图来组织数据，也就不需要位图的全部遍历了。按照一般队列地遍历，每个fd做poll文件操作，检查返回的掩码是否有期待的事件，以及做是否有挂起和错误的必要性检查，如果有事件触发，就可以返回调用了。\n回到poll和select的共同点，面对高并发多连接的应用情境，它们显现出原来没有考虑到的不足，虽然poll比起select又有所改进了。除了上述的关于每次调用都需要做一次从用户空间到内核空间的拷贝，还有这样的问题，就是当处于这样的应用情境时，poll和select会不得不多次操作，并且每次操作都很有可能需要多次进入睡眠状态，也就是多次全部轮询fd，我们应该怎么处理一些会出现重复而无意义的操作。\n这些重复而无意义的操作有：1、从用户到内核空间拷贝，既然长期监视这几个fd，甚至连期待的事件也不会改变，那拷贝无疑就是重复而无意义的，我们可以让内核长期保存所有需要监视的fd甚至期待事件，或者可以再需要时对部分期待事件进行修改；2、将当前线程轮流加入到每个fd对应设备的等待队列，这样做无非是哪一个设备就绪时能够通知进程退出调用，聪明的开发者想到，那就找个“代理”的回调函数，代替当前进程加入fd的等待队列好了（这也是我后来才总结出来，Linux的等待队列，实质上是回调函数队列吧，也可以使用宏来将当前进程“加入”等待队列，其实就是将唤醒当前进程的回调函数加入队列）。这样，像poll系统调用一样，做poll文件操作发现尚未就绪时，它就调用传入的一个回调函数，这是epoll指定的回调函数，它不再像以前的poll系统调用指定的回调函数那样，而是就将那个“代理”的回调函数加入设备的等待队列就好了，这个代理的回调函数就自己乖乖地等待设备就绪时将它唤醒，然后它就把这个设备fd放到一个指定的地方，同时唤醒可能在等待的进程，到这个指定的地方取fd就好了。我们把1和2结合起来就可以这样做了，只拷贝一次fd，一旦确定了fd就可以做poll文件操作，如果有事件当然好啦，马上就把fd放到指定的地方，而通常都是没有的，那就给这个fd的等待队列加一个回调函数，有事件就自动把fd放到指定的地方，当前进程不需要再一个个poll和睡眠等待了。\nepoll机制就是这样改进的了。诚然，fd少的时候，当前进程一个个地等问题不大，可是现在和尚多了，方丈就不好管了。以前设备事件触发时，只负责唤醒当前进程就好了，而当前进程也只能傻傻地在poll里面等待或者循环，再来一次poll，也不知道这个由设备提供的poll性能如何，能不能检查出当前进程已经在等待了就立即返回，当然，我也不明白为什么做了一遍的poll之后，去掉回调函数指针了，还得再做，不是说好了会去唤醒进程的吗？\n现在就让事件触发回调函数多做一步。本来设备还没就绪就调用一个回调函数了，现在再在这个回调函数里面做一个注册另一个回调函数的操作，目的就是使得设备事件触发多走一步，不仅仅是唤醒当前进程，还要把自己的fd放到指定的地方。就像收本子的班长，以前得一个个学生地去问有没有本子，如果没有，它还得等待一段时间而后又继续问，现在好了，只走一次，如果没有本子，班长就告诉大家去那里交本子，当班长想起要取本子，就去那里看看或者等待一定时间后离开，有本子到了就叫醒他，然后取走。这个道理很简单，就是老师和班干们常说的，大家多做一点工作，我的工作就轻松很多了，尤其是需要管理的东西越来越多时。\n这种机制或者说模式，我想在Java的FutureTask里面应该也会用到的，一堆在线程池里面跑着的线程（当然这是任务，不是线程，接口是Callable<V>，不是Runnable.run，是Callable.call，它是可以返回结果的），谁先做好就应该先处理呀，可是难道得一个个问吗？干脆就谁好了，谁就按照既定的操作暴露自己，这样FutureTask的get方法就可以马上知道当前最先完成的线程了，就可以取此线程返回结果了。\nepoll由三个系统调用组成，分别是epoll_create，epoll_ctl和epoll_wait。epoll_create用于创建和初始化一些内部使用的数据结构；epoll_ctl用于添加，删除或者修改指定的fd及其期待的事件，epoll_wait就是用于等待任何先前指定的fd事件。\n","slug":"Linux的IO复用","published":1,"updated":"2016-01-20T04:27:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxffo001m0qi5w7hvwwka","sticky":0},{"title":"博客搬新家啦","date":"2016-01-07T11:12:32.000Z","_content":"&emsp;&emsp;博客搬了新家之后终于又和大家见面了。时逝如隙，从写第一篇博文算起来已经有9年了，说来也是惭愧，直至现在才有了自己的独立博客。其名为林中小灯，同时申请了域名——lightthewoods，意为照亮幽幽森林中的那盏独自闪烁着熠熠光亮的小灯。其实呢，说来说去，还是和我笔名的意义有些关联。虽然我写的东西，分享的内容，在这个时代浩瀚的信息量之中的作用微乎其微，但是我一直会在那里，默默的坚持着。\n\n![lightthewoods](http://7xpwqp.com1.z0.glb.clouddn.com/2016-01-07-01.jpg)\n&emsp;&emsp;从MySpace、新浪博客、51、一直到CSDN，用过的博客平台很多很多。看着这些博客平台起步、繁荣、火爆再到一点儿一点儿没落，也一直忍受着各类博客平台上写博的诸多不爽。这么多年来一直没放到独立博客上其实也有很多这样那样的原因。大学的那个年代，搞独立博客，感觉真的像是黑客或者技术大牛才能搞定的东西。虽然自己也是CS专业，充其量也就会用C写个if、else，倒腾倒腾死记硬背下算法书上的各种题目，以求个门专业课不要挂掉。当时世界上最好的语言PHP也才刚刚展露头角，Nginx在那时看来还是黑客大神们搞得替代apache的玩具，用MySQL的人还不如SQL Server的人数的一个零头。更别说那个年代昂贵的VPS的租用价格了。\n<!--more-->\n&emsp;&emsp;上面列举的这些也是造成各类博客平台能流行一段时间的原因，不管它有这样那样的问题，免费的博客平台终于能满足人们在网络生活中的一项基本需求了。后期随着web技术的日益成熟，搭建web环境变得原来越简单，网络基础设施的价格也越来越便宜，慢慢的博客平台就开始衰落了，逐步的被个人独立博客所替代。\n&emsp;&emsp;说句题外话，最近新浪借助新浪博客10周年的机会配合移动端进行了一次大幅度的改版。虽然出发点不错，但是不管怎么改，技术发展所带来的趋势是没法改变的，只能顺应。所以结果而言也就不言而喻了。\n&emsp;&emsp;后来身边的好多同事、朋友都慢慢的搞了自己的独立博客，尤其是技术博客，如果你放在博客平台上，哪怕是技术门类的博客平台上，也会被人先入为主的认为你的博文技术水平肯定不高。当时迟迟没动手有两个原因吧，首先确实还是自己懒，买空间、买虚拟机、配环境、wordpress、MySQL等等，在工作内容之外把这些东西统统弄一遍想想就不愿意动手，还不用说后期的其实维护上的工作。其次，我当时心里始终觉得在CSDN上有许多志同道合一直支持我的朋友，而且经过首页的推荐，或者论坛里的转发，我的文章能被更多需要的人看到，让他们看到后哪怕是得到一点儿微小的启发。因为在CSDN上的排名曾经一度进入到800名之内，还有编辑看过我写的文章后私信联系我找我出书呢（笑）。当时一直觉得可能搬到独立博客上，也许没了博客平台这个入口大家可能就都看不到了。\n&emsp;&emsp;直到遇到了github page，遇到了hexo静态页面生成框架，已经再也没有不动手的理由了。因对开源的兴趣，github本身就是用的比较多，github page作为一个免费的静态页面容器提供了一切我们所需要的功能。用hexo这样的静态页面生成工具，让我们的博文先生成静态的HTML文件，再进行部署，省去了许多麻烦。再也不用担心以后老眼昏花的时候，不知道那时候php还是不是最好的语言，到时候忽然起意，想看看以前自己写的博文，还要去处理下为什么会报出db connect error的错误。\n&emsp;&emsp;Hexo，因为嫌弃jallar生成页面的速度慢，由一个台湾大学生开发的框架。支持自定义的皮肤，自定义的布局，并且可以多套皮肤随时切换。再也不用受制于博客平台上对页面布局的种种限制。如果懂一些前端技术的话，真的是想怎么改就怎么改。如果不懂也没关系，网上有许多前端大神分享的漂亮的布局皮肤，真的是做到了个性化定制。\n&emsp;&emsp;关于博客流量入口的问题，在全民大数据这个环境下也并不需要过多的担心。类似于今日头条、技术头条、知乎专栏这样的内容聚合平台也如雨后春笋般涌现，主要博客的内容好，完全不用担心入口流量的问题。\n&emsp;&emsp;看到这里，你还有什么理由不去试一下呢~\n\n__PS:__\n&emsp;&emsp;基于github page+Hexo搭建博客的方法可以在网上找到许多优质的相关教程和帖子，这里就不赘述了，我当时参考了[hexo你的博客](http://ibruce.info/2013/11/22/hexo-your-blog/)。\n&emsp;&emsp;在安装node以及hexo等相关node包的时候，最好使用国内淘宝的源，国外的源反正我是连不上的。部署的方式推荐直接用hexo的deploy脚本，直接输入hexo deploy。同时在站点配置文件里配置:\n```Bash\ndeploy:\n    type: git\n    repository: https://github.com/Ethan-Zhang/Ethan-Zhang.github.io.git\n    branch: master\n```\n&emsp;&emsp;主题用到了github上fork和start数最多的issnan大神的[next主题](https://github.com/iissnan/hexo-theme-next)，主要看重了设计的简洁和清爽。\n&emsp;&emsp;图床服务使用的是七牛的免费服务，图片外联都在上面。后期看情况可能也会转成付费用户吧，毕竟好用不贵，当个高级网盘也是不错的。\n&emsp;&emsp;在过程中遇到困难的，欢迎一起交流。\n","source":"_posts/Change-to-GitPage.md","raw":"title: 博客搬新家啦\ndate: 2016-01-07 19:12:32\ntags: [感悟]\n---\n&emsp;&emsp;博客搬了新家之后终于又和大家见面了。时逝如隙，从写第一篇博文算起来已经有9年了，说来也是惭愧，直至现在才有了自己的独立博客。其名为林中小灯，同时申请了域名——lightthewoods，意为照亮幽幽森林中的那盏独自闪烁着熠熠光亮的小灯。其实呢，说来说去，还是和我笔名的意义有些关联。虽然我写的东西，分享的内容，在这个时代浩瀚的信息量之中的作用微乎其微，但是我一直会在那里，默默的坚持着。\n\n![lightthewoods](http://7xpwqp.com1.z0.glb.clouddn.com/2016-01-07-01.jpg)\n&emsp;&emsp;从MySpace、新浪博客、51、一直到CSDN，用过的博客平台很多很多。看着这些博客平台起步、繁荣、火爆再到一点儿一点儿没落，也一直忍受着各类博客平台上写博的诸多不爽。这么多年来一直没放到独立博客上其实也有很多这样那样的原因。大学的那个年代，搞独立博客，感觉真的像是黑客或者技术大牛才能搞定的东西。虽然自己也是CS专业，充其量也就会用C写个if、else，倒腾倒腾死记硬背下算法书上的各种题目，以求个门专业课不要挂掉。当时世界上最好的语言PHP也才刚刚展露头角，Nginx在那时看来还是黑客大神们搞得替代apache的玩具，用MySQL的人还不如SQL Server的人数的一个零头。更别说那个年代昂贵的VPS的租用价格了。\n<!--more-->\n&emsp;&emsp;上面列举的这些也是造成各类博客平台能流行一段时间的原因，不管它有这样那样的问题，免费的博客平台终于能满足人们在网络生活中的一项基本需求了。后期随着web技术的日益成熟，搭建web环境变得原来越简单，网络基础设施的价格也越来越便宜，慢慢的博客平台就开始衰落了，逐步的被个人独立博客所替代。\n&emsp;&emsp;说句题外话，最近新浪借助新浪博客10周年的机会配合移动端进行了一次大幅度的改版。虽然出发点不错，但是不管怎么改，技术发展所带来的趋势是没法改变的，只能顺应。所以结果而言也就不言而喻了。\n&emsp;&emsp;后来身边的好多同事、朋友都慢慢的搞了自己的独立博客，尤其是技术博客，如果你放在博客平台上，哪怕是技术门类的博客平台上，也会被人先入为主的认为你的博文技术水平肯定不高。当时迟迟没动手有两个原因吧，首先确实还是自己懒，买空间、买虚拟机、配环境、wordpress、MySQL等等，在工作内容之外把这些东西统统弄一遍想想就不愿意动手，还不用说后期的其实维护上的工作。其次，我当时心里始终觉得在CSDN上有许多志同道合一直支持我的朋友，而且经过首页的推荐，或者论坛里的转发，我的文章能被更多需要的人看到，让他们看到后哪怕是得到一点儿微小的启发。因为在CSDN上的排名曾经一度进入到800名之内，还有编辑看过我写的文章后私信联系我找我出书呢（笑）。当时一直觉得可能搬到独立博客上，也许没了博客平台这个入口大家可能就都看不到了。\n&emsp;&emsp;直到遇到了github page，遇到了hexo静态页面生成框架，已经再也没有不动手的理由了。因对开源的兴趣，github本身就是用的比较多，github page作为一个免费的静态页面容器提供了一切我们所需要的功能。用hexo这样的静态页面生成工具，让我们的博文先生成静态的HTML文件，再进行部署，省去了许多麻烦。再也不用担心以后老眼昏花的时候，不知道那时候php还是不是最好的语言，到时候忽然起意，想看看以前自己写的博文，还要去处理下为什么会报出db connect error的错误。\n&emsp;&emsp;Hexo，因为嫌弃jallar生成页面的速度慢，由一个台湾大学生开发的框架。支持自定义的皮肤，自定义的布局，并且可以多套皮肤随时切换。再也不用受制于博客平台上对页面布局的种种限制。如果懂一些前端技术的话，真的是想怎么改就怎么改。如果不懂也没关系，网上有许多前端大神分享的漂亮的布局皮肤，真的是做到了个性化定制。\n&emsp;&emsp;关于博客流量入口的问题，在全民大数据这个环境下也并不需要过多的担心。类似于今日头条、技术头条、知乎专栏这样的内容聚合平台也如雨后春笋般涌现，主要博客的内容好，完全不用担心入口流量的问题。\n&emsp;&emsp;看到这里，你还有什么理由不去试一下呢~\n\n__PS:__\n&emsp;&emsp;基于github page+Hexo搭建博客的方法可以在网上找到许多优质的相关教程和帖子，这里就不赘述了，我当时参考了[hexo你的博客](http://ibruce.info/2013/11/22/hexo-your-blog/)。\n&emsp;&emsp;在安装node以及hexo等相关node包的时候，最好使用国内淘宝的源，国外的源反正我是连不上的。部署的方式推荐直接用hexo的deploy脚本，直接输入hexo deploy。同时在站点配置文件里配置:\n```Bash\ndeploy:\n    type: git\n    repository: https://github.com/Ethan-Zhang/Ethan-Zhang.github.io.git\n    branch: master\n```\n&emsp;&emsp;主题用到了github上fork和start数最多的issnan大神的[next主题](https://github.com/iissnan/hexo-theme-next)，主要看重了设计的简洁和清爽。\n&emsp;&emsp;图床服务使用的是七牛的免费服务，图片外联都在上面。后期看情况可能也会转成付费用户吧，毕竟好用不贵，当个高级网盘也是不错的。\n&emsp;&emsp;在过程中遇到困难的，欢迎一起交流。\n","slug":"Change-to-GitPage","published":1,"updated":"2016-01-20T03:24:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cijwaxfft001t0qi5el96folp","sticky":0}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cijwaxfec00030qi5o1enhy68","tag_id":"cijwaxfei00040qi5liwyk109","_id":"cijwaxfel00070qi5nml0hy48"},{"post_id":"cijwaxfec00030qi5o1enhy68","tag_id":"cijwaxfek00050qi5m8ba3gq1","_id":"cijwaxfel00080qi5rp6xuy9v"},{"post_id":"cijwaxfec00030qi5o1enhy68","tag_id":"cijwaxfek00060qi51uc1rk0g","_id":"cijwaxfel00090qi5w95by1jz"},{"post_id":"cijwaxfem000a0qi50aqynbzy","tag_id":"cijwaxfen000b0qi5tt73g2xc","_id":"cijwaxfeo000d0qi5egm9y9yb"},{"post_id":"cijwaxfem000a0qi50aqynbzy","tag_id":"cijwaxfeo000c0qi58x3bwltt","_id":"cijwaxfeo000e0qi5soemys2h"},{"post_id":"cijwaxfeq000f0qi5wt9q1jnt","tag_id":"cijwaxfer000g0qi5fdioia0m","_id":"cijwaxfes000h0qi5bqqj0o3j"},{"post_id":"cijwaxfeu000i0qi56iki5lni","tag_id":"cijwaxfev000j0qi5envgpoga","_id":"cijwaxfew000n0qi52bja4w8h"},{"post_id":"cijwaxfeu000i0qi56iki5lni","tag_id":"cijwaxfev000k0qi5yhrcjwv3","_id":"cijwaxfex000o0qi5kqnhbdcf"},{"post_id":"cijwaxfeu000i0qi56iki5lni","tag_id":"cijwaxfew000l0qi57tqvq99d","_id":"cijwaxfex000p0qi5s7xgmata"},{"post_id":"cijwaxfeu000i0qi56iki5lni","tag_id":"cijwaxfew000m0qi5bsyc61aq","_id":"cijwaxfex000q0qi5tn6gsxex"},{"post_id":"cijwaxfez000r0qi5dt4633rq","tag_id":"cijwaxff1000s0qi52712dxq4","_id":"cijwaxff1000t0qi5zf8dyjnr"},{"post_id":"cijwaxff3000u0qi51e77iasr","tag_id":"cijwaxff4000v0qi5829xaify","_id":"cijwaxff6000y0qi5o12v3s6b"},{"post_id":"cijwaxff3000u0qi51e77iasr","tag_id":"cijwaxff5000w0qi5yetfg0nm","_id":"cijwaxff6000z0qi5mrbqcwnl"},{"post_id":"cijwaxff3000u0qi51e77iasr","tag_id":"cijwaxff6000x0qi5n7d5kk4d","_id":"cijwaxff700100qi5ar337va2"},{"post_id":"cijwaxff800110qi5ucw0cdve","tag_id":"cijwaxffa00120qi5zvl1gvdz","_id":"cijwaxffb00140qi5fy27eovb"},{"post_id":"cijwaxff800110qi5ucw0cdve","tag_id":"cijwaxff4000v0qi5829xaify","_id":"cijwaxffb00150qi5jqf9dm80"},{"post_id":"cijwaxff800110qi5ucw0cdve","tag_id":"cijwaxffa00130qi56p1h8q2u","_id":"cijwaxffb00160qi500nu6l17"},{"post_id":"cijwaxffd00170qi5jfzwbvx3","tag_id":"cijwaxffe00180qi5dsd7i237","_id":"cijwaxfff001a0qi5geoplsvl"},{"post_id":"cijwaxffd00170qi5jfzwbvx3","tag_id":"cijwaxfff00190qi5zqckltqr","_id":"cijwaxfff001b0qi57b2n18h3"},{"post_id":"cijwaxffh001c0qi5shzukqjg","tag_id":"cijwaxffe00180qi5dsd7i237","_id":"cijwaxffj001e0qi5kisz3n9r"},{"post_id":"cijwaxffh001c0qi5shzukqjg","tag_id":"cijwaxffi001d0qi5ufte5qrp","_id":"cijwaxffj001f0qi5dk3pfug0"},{"post_id":"cijwaxffl001g0qi53k1c7zjd","tag_id":"cijwaxffe00180qi5dsd7i237","_id":"cijwaxffn001j0qi5bwsvk50h"},{"post_id":"cijwaxffl001g0qi53k1c7zjd","tag_id":"cijwaxffm001h0qi57oheggr1","_id":"cijwaxffn001k0qi5e4t2m1y7"},{"post_id":"cijwaxffl001g0qi53k1c7zjd","tag_id":"cijwaxffn001i0qi5dujrsryy","_id":"cijwaxffn001l0qi5gp51568a"},{"post_id":"cijwaxffo001m0qi5w7hvwwka","tag_id":"cijwaxffr001n0qi5oxiznxha","_id":"cijwaxffs001q0qi5xo3ahftu"},{"post_id":"cijwaxffo001m0qi5w7hvwwka","tag_id":"cijwaxffr001o0qi52fby3f3r","_id":"cijwaxffs001r0qi5d3m93k3z"},{"post_id":"cijwaxffo001m0qi5w7hvwwka","tag_id":"cijwaxffs001p0qi5m5lva0tq","_id":"cijwaxffs001s0qi5aujuaizr"},{"post_id":"cijwaxfft001t0qi5el96folp","tag_id":"cijwaxfer000g0qi5fdioia0m","_id":"cijwaxffw001u0qi5o7dbjyvl"}],"Tag":[{"name":"C/C++","_id":"cijwaxfei00040qi5liwyk109"},{"name":"算法","_id":"cijwaxfek00050qi5m8ba3gq1"},{"name":"列表","_id":"cijwaxfek00060qi51uc1rk0g"},{"name":"架构","_id":"cijwaxfen000b0qi5tt73g2xc"},{"name":"面试","_id":"cijwaxfeo000c0qi58x3bwltt"},{"name":"感悟","_id":"cijwaxfer000g0qi5fdioia0m"},{"name":"uwsgi","_id":"cijwaxfev000j0qi5envgpoga"},{"name":"多线程","_id":"cijwaxfev000k0qi5yhrcjwv3"},{"name":"Python C API","_id":"cijwaxfew000l0qi57tqvq99d"},{"name":"C调用Python","_id":"cijwaxfew000m0qi5bsyc61aq"},{"name":"memcached","_id":"cijwaxff1000s0qi52712dxq4"},{"name":"Tornado","_id":"cijwaxff4000v0qi5829xaify"},{"name":"异步","_id":"cijwaxff5000w0qi5yetfg0nm"},{"name":"开源","_id":"cijwaxff6000x0qi5n7d5kk4d"},{"name":"Python","_id":"cijwaxffa00120qi5zvl1gvdz"},{"name":"日志切分","_id":"cijwaxffa00130qi56p1h8q2u"},{"name":"OpenStack","_id":"cijwaxffe00180qi5dsd7i237"},{"name":"cloud-init","_id":"cijwaxfff00190qi5zqckltqr"},{"name":"Nova","_id":"cijwaxffi001d0qi5ufte5qrp"},{"name":"AMQP","_id":"cijwaxffm001h0qi57oheggr1"},{"name":"kombu","_id":"cijwaxffn001i0qi5dujrsryy"},{"name":"IO复用","_id":"cijwaxffr001n0qi5oxiznxha"},{"name":"LINUX","_id":"cijwaxffr001o0qi52fby3f3r"},{"name":"高并发","_id":"cijwaxffs001p0qi5m5lva0tq"}]}}